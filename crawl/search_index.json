[{"module": "numpy._core.multiarray", "name": "empty_like", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "prototype", "datatype": null}, {"name": "dtype", "datatype": null}, {"name": "order", "datatype": null}, {"name": "subok", "datatype": null}, {"name": "shape", "datatype": null}], "source_code": "def empty_like(prototype, dtype=None, order=None, subok=None, shape=None):\n    \"\"\"\n    empty_like(prototype, dtype=None, order='K', subok=True, shape=None)\n\n    Return a new array with the same shape and type as a given array.\n\n    Parameters\n    ----------\n    prototype : array_like\n        The shape and data-type of `prototype` define these same attributes\n        of the returned array.\n    dtype : data-type, optional\n        Overrides the data type of the result.\n\n        .. versionadded:: 1.6.0\n    order : {'C', 'F', 'A', or 'K'}, optional\n        Overrides the memory layout of the result. 'C' means C-order,\n        'F' means F-order, 'A' means 'F' if `prototype` is Fortran\n        contiguous, 'C' otherwise. 'K' means match the layout of `prototype`\n        as closely as possible.\n\n        .. versionadded:: 1.6.0\n    subok : bool, optional.\n        If True, then the newly created array will use the sub-class\n        type of `prototype`, otherwise it will be a base-class array. Defaults\n        to True.\n    shape : int or sequence of ints, optional.\n        Overrides the shape of the result. If order='K' and the number of\n        dimensions is unchanged, will try to keep order, otherwise,\n        order='C' is implied.\n\n        .. versionadded:: 1.17.0\n\n    Returns\n    -------\n    out : ndarray\n        Array of uninitialized (arbitrary) data with the same\n        shape and type as `prototype`.\n\n    See Also\n    --------\n    ones_like : Return an array of ones with shape and type of input.\n    zeros_like : Return an array of zeros with shape and type of input.\n    full_like : Return a new array with shape of input filled with value.\n    empty : Return a new uninitialized array.\n\n    Notes\n    -----\n    This function does *not* initialize the returned array; to do that use\n    `zeros_like` or `ones_like` instead.  It may be marginally faster than\n    the functions that do set the array values.\n\n    Examples\n    --------\n    >>> a = ([1,2,3], [4,5,6])                         # a is array-like\n    >>> np.empty_like(a)\n    array([[-1073741821, -1073741821,           3],    # uninitialized\n           [          0,           0, -1073741821]])\n    >>> a = np.array([[1., 2., 3.],[4.,5.,6.]])\n    >>> np.empty_like(a)\n    array([[ -2.00000715e+000,   1.48219694e-323,  -2.00000572e+000], # uninitialized\n           [  4.38791518e-305,  -2.00000715e+000,   4.17269252e-309]])\n\n    \"\"\"\n    return (prototype,)"}, {"module": "numpy._core.multiarray", "name": "concatenate", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher", "arrays.append"], "arguments": [{"name": "arrays", "datatype": null}, {"name": "axis", "datatype": null}, {"name": "out", "datatype": null}], "source_code": "def concatenate(arrays, axis=None, out=None, *, dtype=None, casting=None):\n    \"\"\"\n    concatenate((a1, a2, ...), axis=0, out=None, dtype=None, casting=\"same_kind\")\n\n    Join a sequence of arrays along an existing axis.\n\n    Parameters\n    ----------\n    a1, a2, ... : sequence of array_like\n        The arrays must have the same shape, except in the dimension\n        corresponding to `axis` (the first, by default).\n    axis : int, optional\n        The axis along which the arrays will be joined.  If axis is None,\n        arrays are flattened before use.  Default is 0.\n    out : ndarray, optional\n        If provided, the destination to place the result. The shape must be\n        correct, matching that of what concatenate would have returned if no\n        out argument were specified.\n    dtype : str or dtype\n        If provided, the destination array will have this dtype. Cannot be\n        provided together with `out`.\n\n        .. versionadded:: 1.20.0\n\n    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n        Controls what kind of data casting may occur. Defaults to 'same_kind'.\n\n        .. versionadded:: 1.20.0\n\n    Returns\n    -------\n    res : ndarray\n        The concatenated array.\n\n    See Also\n    --------\n    ma.concatenate : Concatenate function that preserves input masks.\n    array_split : Split an array into multiple sub-arrays of equal or\n                  near-equal size.\n    split : Split array into a list of multiple sub-arrays of equal size.\n    hsplit : Split array into multiple sub-arrays horizontally (column wise).\n    vsplit : Split array into multiple sub-arrays vertically (row wise).\n    dsplit : Split array into multiple sub-arrays along the 3rd axis (depth).\n    stack : Stack a sequence of arrays along a new axis.\n    block : Assemble arrays from blocks.\n    hstack : Stack arrays in sequence horizontally (column wise).\n    vstack : Stack arrays in sequence vertically (row wise).\n    dstack : Stack arrays in sequence depth wise (along third dimension).\n    column_stack : Stack 1-D arrays as columns into a 2-D array.\n\n    Notes\n    -----\n    When one or more of the arrays to be concatenated is a MaskedArray,\n    this function will return a MaskedArray object instead of an ndarray,\n    but the input masks are *not* preserved. In cases where a MaskedArray\n    is expected as input, use the ma.concatenate function from the masked\n    array module instead.\n\n    Examples\n    --------\n    >>> a = np.array([[1, 2], [3, 4]])\n    >>> b = np.array([[5, 6]])\n    >>> np.concatenate((a, b), axis=0)\n    array([[1, 2],\n           [3, 4],\n           [5, 6]])\n    >>> np.concatenate((a, b.T), axis=1)\n    array([[1, 2, 5],\n           [3, 4, 6]])\n    >>> np.concatenate((a, b), axis=None)\n    array([1, 2, 3, 4, 5, 6])\n\n    This function will not preserve masking of MaskedArray inputs.\n\n    >>> a = np.ma.arange(3)\n    >>> a[1] = np.ma.masked\n    >>> b = np.arange(2, 5)\n    >>> a\n    masked_array(data=[0, --, 2],\n                 mask=[False,  True, False],\n           fill_value=999999)\n    >>> b\n    array([2, 3, 4])\n    >>> np.concatenate([a, b])\n    masked_array(data=[0, 1, 2, 2, 3, 4],\n                 mask=False,\n           fill_value=999999)\n    >>> np.ma.concatenate([a, b])\n    masked_array(data=[0, --, 2, 2, 3, 4],\n                 mask=[False,  True, False, False, False, False],\n           fill_value=999999)\n\n    \"\"\"\n    if out is not None:\n        # optimize for the typical case where only arrays is provided\n        arrays = list(arrays)\n        arrays.append(out)\n    return arrays"}, {"module": "numpy._core.multiarray", "name": "inner", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "a", "datatype": null}, {"name": "b", "datatype": null}], "source_code": "def inner(a, b):\n    \"\"\"\n    inner(a, b, /)\n\n    Inner product of two arrays.\n\n    Ordinary inner product of vectors for 1-D arrays (without complex\n    conjugation), in higher dimensions a sum product over the last axes.\n\n    Parameters\n    ----------\n    a, b : array_like\n        If `a` and `b` are nonscalar, their last dimensions must match.\n\n    Returns\n    -------\n    out : ndarray\n        If `a` and `b` are both\n        scalars or both 1-D arrays then a scalar is returned; otherwise\n        an array is returned.\n        ``out.shape = (*a.shape[:-1], *b.shape[:-1])``\n\n    Raises\n    ------\n    ValueError\n        If both `a` and `b` are nonscalar and their last dimensions have\n        different sizes.\n\n    See Also\n    --------\n    tensordot : Sum products over arbitrary axes.\n    dot : Generalised matrix product, using second last dimension of `b`.\n    einsum : Einstein summation convention.\n\n    Notes\n    -----\n    For vectors (1-D arrays) it computes the ordinary inner-product::\n\n        np.inner(a, b) = sum(a[:]*b[:])\n\n    More generally, if ``ndim(a) = r > 0`` and ``ndim(b) = s > 0``::\n\n        np.inner(a, b) = np.tensordot(a, b, axes=(-1,-1))\n\n    or explicitly::\n\n        np.inner(a, b)[i0,...,ir-2,j0,...,js-2]\n             = sum(a[i0,...,ir-2,:]*b[j0,...,js-2,:])\n\n    In addition `a` or `b` may be scalars, in which case::\n\n       np.inner(a,b) = a*b\n\n    Examples\n    --------\n    Ordinary inner product for vectors:\n\n    >>> a = np.array([1,2,3])\n    >>> b = np.array([0,1,0])\n    >>> np.inner(a, b)\n    2\n\n    Some multidimensional examples:\n\n    >>> a = np.arange(24).reshape((2,3,4))\n    >>> b = np.arange(4)\n    >>> c = np.inner(a, b)\n    >>> c.shape\n    (2, 3)\n    >>> c\n    array([[ 14,  38,  62],\n           [ 86, 110, 134]])\n\n    >>> a = np.arange(2).reshape((1,1,2))\n    >>> b = np.arange(6).reshape((3,2))\n    >>> c = np.inner(a, b)\n    >>> c.shape\n    (1, 1, 3)\n    >>> c\n    array([[[1, 3, 5]]])\n\n    An example where `b` is a scalar:\n\n    >>> np.inner(np.eye(2), 7)\n    array([[7., 0.],\n           [0., 7.]])\n\n    \"\"\"\n    return (a, b)"}, {"module": "numpy._core.multiarray", "name": "where", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "condition", "datatype": null}, {"name": "x", "datatype": null}, {"name": "y", "datatype": null}], "source_code": "def where(condition, x=None, y=None):\n    \"\"\"\n    where(condition, [x, y], /)\n\n    Return elements chosen from `x` or `y` depending on `condition`.\n\n    .. note::\n        When only `condition` is provided, this function is a shorthand for\n        ``np.asarray(condition).nonzero()``. Using `nonzero` directly should be\n        preferred, as it behaves correctly for subclasses. The rest of this\n        documentation covers only the case where all three arguments are\n        provided.\n\n    Parameters\n    ----------\n    condition : array_like, bool\n        Where True, yield `x`, otherwise yield `y`.\n    x, y : array_like\n        Values from which to choose. `x`, `y` and `condition` need to be\n        broadcastable to some shape.\n\n    Returns\n    -------\n    out : ndarray\n        An array with elements from `x` where `condition` is True, and elements\n        from `y` elsewhere.\n\n    See Also\n    --------\n    choose\n    nonzero : The function that is called when x and y are omitted\n\n    Notes\n    -----\n    If all the arrays are 1-D, `where` is equivalent to::\n\n        [xv if c else yv\n         for c, xv, yv in zip(condition, x, y)]\n\n    Examples\n    --------\n    >>> a = np.arange(10)\n    >>> a\n    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n    >>> np.where(a < 5, a, 10*a)\n    array([ 0,  1,  2,  3,  4, 50, 60, 70, 80, 90])\n\n    This can be used on multidimensional arrays too:\n\n    >>> np.where([[True, False], [True, True]],\n    ...          [[1, 2], [3, 4]],\n    ...          [[9, 8], [7, 6]])\n    array([[1, 8],\n           [3, 4]])\n\n    The shapes of x, y, and the condition are broadcast together:\n\n    >>> x, y = np.ogrid[:3, :4]\n    >>> np.where(x < y, x, 10 + y)  # both x and 10+y are broadcast\n    array([[10,  0,  0,  0],\n           [10, 11,  1,  1],\n           [10, 11, 12,  2]])\n\n    >>> a = np.array([[0, 1, 2],\n    ...               [0, 2, 4],\n    ...               [0, 3, 6]])\n    >>> np.where(a < 4, a, -1)  # -1 is broadcast\n    array([[ 0,  1,  2],\n           [ 0,  2, -1],\n           [ 0,  3, -1]])\n    \"\"\"\n    return (condition, x, y)"}, {"module": "numpy._core.multiarray", "name": "lexsort", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "keys", "datatype": null}, {"name": "axis", "datatype": null}], "source_code": "def lexsort(keys, axis=None):\n    \"\"\"\n    lexsort(keys, axis=-1)\n\n    Perform an indirect stable sort using a sequence of keys.\n\n    Given multiple sorting keys, which can be interpreted as columns in a\n    spreadsheet, lexsort returns an array of integer indices that describes\n    the sort order by multiple columns. The last key in the sequence is used\n    for the primary sort order, the second-to-last key for the secondary sort\n    order, and so on. The keys argument must be a sequence of objects that\n    can be converted to arrays of the same shape. If a 2D array is provided\n    for the keys argument, its rows are interpreted as the sorting keys and\n    sorting is according to the last row, second last row etc.\n\n    Parameters\n    ----------\n    keys : (k, N) array or tuple containing k (N,)-shaped sequences\n        The `k` different \"columns\" to be sorted.  The last column (or row if\n        `keys` is a 2D array) is the primary sort key.\n    axis : int, optional\n        Axis to be indirectly sorted.  By default, sort over the last axis.\n\n    Returns\n    -------\n    indices : (N,) ndarray of ints\n        Array of indices that sort the keys along the specified axis.\n\n    See Also\n    --------\n    argsort : Indirect sort.\n    ndarray.sort : In-place sort.\n    sort : Return a sorted copy of an array.\n\n    Examples\n    --------\n    Sort names: first by surname, then by name.\n\n    >>> surnames =    ('Hertz',    'Galilei', 'Hertz')\n    >>> first_names = ('Heinrich', 'Galileo', 'Gustav')\n    >>> ind = np.lexsort((first_names, surnames))\n    >>> ind\n    array([1, 2, 0])\n\n    >>> [surnames[i] + \", \" + first_names[i] for i in ind]\n    ['Galilei, Galileo', 'Hertz, Gustav', 'Hertz, Heinrich']\n\n    Sort two columns of numbers:\n\n    >>> a = [1,5,1,4,3,4,4] # First column\n    >>> b = [9,4,0,4,0,2,1] # Second column\n    >>> ind = np.lexsort((b,a)) # Sort by a, then by b\n    >>> ind\n    array([2, 0, 4, 6, 5, 3, 1])\n\n    >>> [(a[i],b[i]) for i in ind]\n    [(1, 0), (1, 9), (3, 0), (4, 1), (4, 2), (4, 4), (5, 4)]\n\n    Note that sorting is first according to the elements of ``a``.\n    Secondary sorting is according to the elements of ``b``.\n\n    A normal ``argsort`` would have yielded:\n\n    >>> [(a[i],b[i]) for i in np.argsort(a)]\n    [(1, 9), (1, 0), (3, 0), (4, 4), (4, 2), (4, 1), (5, 4)]\n\n    Structured arrays are sorted lexically by ``argsort``:\n\n    >>> x = np.array([(1,9), (5,4), (1,0), (4,4), (3,0), (4,2), (4,1)],\n    ...              dtype=np.dtype([('x', int), ('y', int)]))\n\n    >>> np.argsort(x) # or np.argsort(x, order=('x', 'y'))\n    array([2, 0, 4, 6, 5, 3, 1])\n\n    \"\"\"\n    if isinstance(keys, tuple):\n        return keys\n    else:\n        return (keys,)"}, {"module": "numpy._core.multiarray", "name": "can_cast", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "from_", "datatype": null}, {"name": "to", "datatype": null}, {"name": "casting", "datatype": null}], "source_code": "def can_cast(from_, to, casting=None):\n    \"\"\"\n    can_cast(from_, to, casting='safe')\n\n    Returns True if cast between data types can occur according to the\n    casting rule.  If from is a scalar or array scalar, also returns\n    True if the scalar value can be cast without overflow or truncation\n    to an integer.\n\n    Parameters\n    ----------\n    from_ : dtype, dtype specifier, scalar, or array\n        Data type, scalar, or array to cast from.\n    to : dtype or dtype specifier\n        Data type to cast to.\n    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n        Controls what kind of data casting may occur.\n\n          * 'no' means the data types should not be cast at all.\n          * 'equiv' means only byte-order changes are allowed.\n          * 'safe' means only casts which can preserve values are allowed.\n          * 'same_kind' means only safe casts or casts within a kind,\n            like float64 to float32, are allowed.\n          * 'unsafe' means any data conversions may be done.\n\n    Returns\n    -------\n    out : bool\n        True if cast can occur according to the casting rule.\n\n    Notes\n    -----\n    .. versionchanged:: 1.17.0\n       Casting between a simple data type and a structured one is possible only\n       for \"unsafe\" casting.  Casting to multiple fields is allowed, but\n       casting from multiple fields is not.\n\n    .. versionchanged:: 1.9.0\n       Casting from numeric to string types in 'safe' casting mode requires\n       that the string dtype length is long enough to store the maximum\n       integer/float value converted.\n\n    See also\n    --------\n    dtype, result_type\n\n    Examples\n    --------\n    Basic examples\n\n    >>> np.can_cast(np.int32, np.int64)\n    True\n    >>> np.can_cast(np.float64, complex)\n    True\n    >>> np.can_cast(complex, float)\n    False\n\n    >>> np.can_cast('i8', 'f8')\n    True\n    >>> np.can_cast('i8', 'f4')\n    False\n    >>> np.can_cast('i4', 'S4')\n    False\n\n    Casting scalars\n\n    >>> np.can_cast(100, 'i1')\n    True\n    >>> np.can_cast(150, 'i1')\n    False\n    >>> np.can_cast(150, 'u1')\n    True\n\n    >>> np.can_cast(3.5e100, np.float32)\n    False\n    >>> np.can_cast(1000.0, np.float32)\n    True\n\n    Array scalar checks the value, array does not\n\n    >>> np.can_cast(np.array(1000.0), np.float32)\n    True\n    >>> np.can_cast(np.array([1000.0]), np.float32)\n    False\n\n    Using the casting rules\n\n    >>> np.can_cast('i8', 'i8', 'no')\n    True\n    >>> np.can_cast('<i8', '>i8', 'no')\n    False\n\n    >>> np.can_cast('<i8', '>i8', 'equiv')\n    True\n    >>> np.can_cast('<i4', '>i8', 'equiv')\n    False\n\n    >>> np.can_cast('<i4', '>i8', 'safe')\n    True\n    >>> np.can_cast('<i8', '>i4', 'safe')\n    False\n\n    >>> np.can_cast('<i8', '>i4', 'same_kind')\n    True\n    >>> np.can_cast('<i8', '>u4', 'same_kind')\n    False\n\n    >>> np.can_cast('<i8', '>u4', 'unsafe')\n    True\n\n    \"\"\"\n    return (from_,)"}, {"module": "numpy._core.multiarray", "name": "min_scalar_type", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "a", "datatype": null}], "source_code": "def min_scalar_type(a):\n    \"\"\"\n    min_scalar_type(a, /)\n\n    For scalar ``a``, returns the data type with the smallest size\n    and smallest scalar kind which can hold its value.  For non-scalar\n    array ``a``, returns the vector's dtype unmodified.\n\n    Floating point values are not demoted to integers,\n    and complex values are not demoted to floats.\n\n    Parameters\n    ----------\n    a : scalar or array_like\n        The value whose minimal data type is to be found.\n\n    Returns\n    -------\n    out : dtype\n        The minimal data type.\n\n    Notes\n    -----\n    .. versionadded:: 1.6.0\n\n    See Also\n    --------\n    result_type, promote_types, dtype, can_cast\n\n    Examples\n    --------\n    >>> np.min_scalar_type(10)\n    dtype('uint8')\n\n    >>> np.min_scalar_type(-260)\n    dtype('int16')\n\n    >>> np.min_scalar_type(3.1)\n    dtype('float16')\n\n    >>> np.min_scalar_type(1e50)\n    dtype('float64')\n\n    >>> np.min_scalar_type(np.arange(4,dtype='f8'))\n    dtype('float64')\n\n    \"\"\"\n    return (a,)"}, {"module": "numpy._core.multiarray", "name": "result_type", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [], "source_code": "def result_type(*arrays_and_dtypes):\n    \"\"\"\n    result_type(*arrays_and_dtypes)\n\n    Returns the type that results from applying the NumPy\n    type promotion rules to the arguments.\n\n    Type promotion in NumPy works similarly to the rules in languages\n    like C++, with some slight differences.  When both scalars and\n    arrays are used, the array's type takes precedence and the actual value\n    of the scalar is taken into account.\n\n    For example, calculating 3*a, where a is an array of 32-bit floats,\n    intuitively should result in a 32-bit float output.  If the 3 is a\n    32-bit integer, the NumPy rules indicate it can't convert losslessly\n    into a 32-bit float, so a 64-bit float should be the result type.\n    By examining the value of the constant, '3', we see that it fits in\n    an 8-bit integer, which can be cast losslessly into the 32-bit float.\n\n    Parameters\n    ----------\n    arrays_and_dtypes : list of arrays and dtypes\n        The operands of some operation whose result type is needed.\n\n    Returns\n    -------\n    out : dtype\n        The result type.\n\n    See also\n    --------\n    dtype, promote_types, min_scalar_type, can_cast\n\n    Notes\n    -----\n    .. versionadded:: 1.6.0\n\n    The specific algorithm used is as follows.\n\n    Categories are determined by first checking which of boolean,\n    integer (int/uint), or floating point (float/complex) the maximum\n    kind of all the arrays and the scalars are.\n\n    If there are only scalars or the maximum category of the scalars\n    is higher than the maximum category of the arrays,\n    the data types are combined with :func:`promote_types`\n    to produce the return value.\n\n    Otherwise, `min_scalar_type` is called on each scalar, and\n    the resulting data types are all combined with :func:`promote_types`\n    to produce the return value.\n\n    The set of int values is not a subset of the uint values for types\n    with the same number of bits, something not reflected in\n    :func:`min_scalar_type`, but handled as a special case in `result_type`.\n\n    Examples\n    --------\n    >>> np.result_type(3, np.arange(7, dtype='i1'))\n    dtype('int8')\n\n    >>> np.result_type('i4', 'c8')\n    dtype('complex128')\n\n    >>> np.result_type(3.0, -2)\n    dtype('float64')\n\n    \"\"\"\n    return arrays_and_dtypes"}, {"module": "numpy._core.multiarray", "name": "dot", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "a", "datatype": null}, {"name": "b", "datatype": null}, {"name": "out", "datatype": null}], "source_code": "def dot(a, b, out=None):\n    \"\"\"\n    dot(a, b, out=None)\n\n    Dot product of two arrays. Specifically,\n\n    - If both `a` and `b` are 1-D arrays, it is inner product of vectors\n      (without complex conjugation).\n\n    - If both `a` and `b` are 2-D arrays, it is matrix multiplication,\n      but using :func:`matmul` or ``a @ b`` is preferred.\n\n    - If either `a` or `b` is 0-D (scalar), it is equivalent to\n      :func:`multiply` and using ``numpy.multiply(a, b)`` or ``a * b`` is\n      preferred.\n\n    - If `a` is an N-D array and `b` is a 1-D array, it is a sum product over\n      the last axis of `a` and `b`.\n\n    - If `a` is an N-D array and `b` is an M-D array (where ``M>=2``), it is a\n      sum product over the last axis of `a` and the second-to-last axis of\n      `b`::\n\n        dot(a, b)[i,j,k,m] = sum(a[i,j,:] * b[k,:,m])\n\n    It uses an optimized BLAS library when possible (see `numpy.linalg`).\n\n    Parameters\n    ----------\n    a : array_like\n        First argument.\n    b : array_like\n        Second argument.\n    out : ndarray, optional\n        Output argument. This must have the exact kind that would be returned\n        if it was not used. In particular, it must have the right type, must be\n        C-contiguous, and its dtype must be the dtype that would be returned\n        for `dot(a,b)`. This is a performance feature. Therefore, if these\n        conditions are not met, an exception is raised, instead of attempting\n        to be flexible.\n\n    Returns\n    -------\n    output : ndarray\n        Returns the dot product of `a` and `b`.  If `a` and `b` are both\n        scalars or both 1-D arrays then a scalar is returned; otherwise\n        an array is returned.\n        If `out` is given, then it is returned.\n\n    Raises\n    ------\n    ValueError\n        If the last dimension of `a` is not the same size as\n        the second-to-last dimension of `b`.\n\n    See Also\n    --------\n    vdot : Complex-conjugating dot product.\n    tensordot : Sum products over arbitrary axes.\n    einsum : Einstein summation convention.\n    matmul : '@' operator as method with out parameter.\n    linalg.multi_dot : Chained dot product.\n\n    Examples\n    --------\n    >>> np.dot(3, 4)\n    12\n\n    Neither argument is complex-conjugated:\n\n    >>> np.dot([2j, 3j], [2j, 3j])\n    (-13+0j)\n\n    For 2-D arrays it is the matrix product:\n\n    >>> a = [[1, 0], [0, 1]]\n    >>> b = [[4, 1], [2, 2]]\n    >>> np.dot(a, b)\n    array([[4, 1],\n           [2, 2]])\n\n    >>> a = np.arange(3*4*5*6).reshape((3,4,5,6))\n    >>> b = np.arange(3*4*5*6)[::-1].reshape((5,4,6,3))\n    >>> np.dot(a, b)[2,3,2,1,2,2]\n    499128\n    >>> sum(a[2,3,2,:] * b[1,2,:,2])\n    499128\n\n    \"\"\"\n    return (a, b, out)"}, {"module": "numpy._core.multiarray", "name": "vdot", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "a", "datatype": null}, {"name": "b", "datatype": null}], "source_code": "def vdot(a, b):\n    \"\"\"\n    vdot(a, b, /)\n\n    Return the dot product of two vectors.\n\n    The vdot(`a`, `b`) function handles complex numbers differently than\n    dot(`a`, `b`).  If the first argument is complex the complex conjugate\n    of the first argument is used for the calculation of the dot product.\n\n    Note that `vdot` handles multidimensional arrays differently than `dot`:\n    it does *not* perform a matrix product, but flattens input arguments\n    to 1-D vectors first. Consequently, it should only be used for vectors.\n\n    Parameters\n    ----------\n    a : array_like\n        If `a` is complex the complex conjugate is taken before calculation\n        of the dot product.\n    b : array_like\n        Second argument to the dot product.\n\n    Returns\n    -------\n    output : ndarray\n        Dot product of `a` and `b`.  Can be an int, float, or\n        complex depending on the types of `a` and `b`.\n\n    See Also\n    --------\n    dot : Return the dot product without using the complex conjugate of the\n          first argument.\n\n    Examples\n    --------\n    >>> a = np.array([1+2j,3+4j])\n    >>> b = np.array([5+6j,7+8j])\n    >>> np.vdot(a, b)\n    (70-8j)\n    >>> np.vdot(b, a)\n    (70+8j)\n\n    Note that higher-dimensional arrays are flattened!\n\n    >>> a = np.array([[1, 4], [5, 6]])\n    >>> b = np.array([[4, 1], [2, 2]])\n    >>> np.vdot(a, b)\n    30\n    >>> np.vdot(b, a)\n    30\n    >>> 1*4 + 4*1 + 5*2 + 6*2\n    30\n\n    \"\"\"\n    return (a, b)"}, {"module": "numpy._core.multiarray", "name": "bincount", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "x", "datatype": null}, {"name": "weights", "datatype": null}, {"name": "minlength", "datatype": null}], "source_code": "def bincount(x, weights=None, minlength=None):\n    \"\"\"\n    bincount(x, /, weights=None, minlength=0)\n\n    Count number of occurrences of each value in array of non-negative ints.\n\n    The number of bins (of size 1) is one larger than the largest value in\n    `x`. If `minlength` is specified, there will be at least this number\n    of bins in the output array (though it will be longer if necessary,\n    depending on the contents of `x`).\n    Each bin gives the number of occurrences of its index value in `x`.\n    If `weights` is specified the input array is weighted by it, i.e. if a\n    value ``n`` is found at position ``i``, ``out[n] += weight[i]`` instead\n    of ``out[n] += 1``.\n\n    Parameters\n    ----------\n    x : array_like, 1 dimension, nonnegative ints\n        Input array.\n    weights : array_like, optional\n        Weights, array of the same shape as `x`.\n    minlength : int, optional\n        A minimum number of bins for the output array.\n\n        .. versionadded:: 1.6.0\n\n    Returns\n    -------\n    out : ndarray of ints\n        The result of binning the input array.\n        The length of `out` is equal to ``np.amax(x)+1``.\n\n    Raises\n    ------\n    ValueError\n        If the input is not 1-dimensional, or contains elements with negative\n        values, or if `minlength` is negative.\n    TypeError\n        If the type of the input is float or complex.\n\n    See Also\n    --------\n    histogram, digitize, unique\n\n    Examples\n    --------\n    >>> np.bincount(np.arange(5))\n    array([1, 1, 1, 1, 1])\n    >>> np.bincount(np.array([0, 1, 1, 3, 2, 1, 7]))\n    array([1, 3, 1, 1, 0, 0, 0, 1])\n\n    >>> x = np.array([0, 1, 1, 3, 2, 1, 7, 23])\n    >>> np.bincount(x).size == np.amax(x)+1\n    True\n\n    The input array needs to be of integer dtype, otherwise a\n    TypeError is raised:\n\n    >>> np.bincount(np.arange(5, dtype=float))\n    Traceback (most recent call last):\n      ...\n    TypeError: Cannot cast array data from dtype('float64') to dtype('int64')\n    according to the rule 'safe'\n\n    A possible use of ``bincount`` is to perform sums over\n    variable-size chunks of an array, using the ``weights`` keyword.\n\n    >>> w = np.array([0.3, 0.5, 0.2, 0.7, 1., -0.6]) # weights\n    >>> x = np.array([0, 1, 1, 2, 2, 2])\n    >>> np.bincount(x,  weights=w)\n    array([ 0.3,  0.7,  1.1])\n\n    \"\"\"\n    return (x, weights)"}, {"module": "numpy._core.multiarray", "name": "ravel_multi_index", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "multi_index", "datatype": null}, {"name": "dims", "datatype": null}, {"name": "mode", "datatype": null}, {"name": "order", "datatype": null}], "source_code": "def ravel_multi_index(multi_index, dims, mode=None, order=None):\n    \"\"\"\n    ravel_multi_index(multi_index, dims, mode='raise', order='C')\n\n    Converts a tuple of index arrays into an array of flat\n    indices, applying boundary modes to the multi-index.\n\n    Parameters\n    ----------\n    multi_index : tuple of array_like\n        A tuple of integer arrays, one array for each dimension.\n    dims : tuple of ints\n        The shape of array into which the indices from ``multi_index`` apply.\n    mode : {'raise', 'wrap', 'clip'}, optional\n        Specifies how out-of-bounds indices are handled.  Can specify\n        either one mode or a tuple of modes, one mode per index.\n\n        * 'raise' -- raise an error (default)\n        * 'wrap' -- wrap around\n        * 'clip' -- clip to the range\n\n        In 'clip' mode, a negative index which would normally\n        wrap will clip to 0 instead.\n    order : {'C', 'F'}, optional\n        Determines whether the multi-index should be viewed as\n        indexing in row-major (C-style) or column-major\n        (Fortran-style) order.\n\n    Returns\n    -------\n    raveled_indices : ndarray\n        An array of indices into the flattened version of an array\n        of dimensions ``dims``.\n\n    See Also\n    --------\n    unravel_index\n\n    Notes\n    -----\n    .. versionadded:: 1.6.0\n\n    Examples\n    --------\n    >>> arr = np.array([[3,6,6],[4,5,1]])\n    >>> np.ravel_multi_index(arr, (7,6))\n    array([22, 41, 37])\n    >>> np.ravel_multi_index(arr, (7,6), order='F')\n    array([31, 41, 13])\n    >>> np.ravel_multi_index(arr, (4,6), mode='clip')\n    array([22, 23, 19])\n    >>> np.ravel_multi_index(arr, (4,4), mode=('clip','wrap'))\n    array([12, 13, 13])\n\n    >>> np.ravel_multi_index((3,1,4,1), (6,7,8,9))\n    1621\n    \"\"\"\n    return multi_index"}, {"module": "numpy._core.multiarray", "name": "unravel_index", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "indices", "datatype": null}, {"name": "shape", "datatype": null}, {"name": "order", "datatype": null}], "source_code": "def unravel_index(indices, shape=None, order=None):\n    \"\"\"\n    unravel_index(indices, shape, order='C')\n\n    Converts a flat index or array of flat indices into a tuple\n    of coordinate arrays.\n\n    Parameters\n    ----------\n    indices : array_like\n        An integer array whose elements are indices into the flattened\n        version of an array of dimensions ``shape``. Before version 1.6.0,\n        this function accepted just one index value.\n    shape : tuple of ints\n        The shape of the array to use for unraveling ``indices``.\n\n        .. versionchanged:: 1.16.0\n            Renamed from ``dims`` to ``shape``.\n\n    order : {'C', 'F'}, optional\n        Determines whether the indices should be viewed as indexing in\n        row-major (C-style) or column-major (Fortran-style) order.\n\n        .. versionadded:: 1.6.0\n\n    Returns\n    -------\n    unraveled_coords : tuple of ndarray\n        Each array in the tuple has the same shape as the ``indices``\n        array.\n\n    See Also\n    --------\n    ravel_multi_index\n\n    Examples\n    --------\n    >>> np.unravel_index([22, 41, 37], (7,6))\n    (array([3, 6, 6]), array([4, 5, 1]))\n    >>> np.unravel_index([31, 41, 13], (7,6), order='F')\n    (array([3, 6, 6]), array([4, 5, 1]))\n\n    >>> np.unravel_index(1621, (6,7,8,9))\n    (3, 1, 4, 1)\n\n    \"\"\"\n    return (indices,)"}, {"module": "numpy._core.multiarray", "name": "copyto", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "dst", "datatype": null}, {"name": "src", "datatype": null}, {"name": "casting", "datatype": null}, {"name": "where", "datatype": null}], "source_code": "def copyto(dst, src, casting=None, where=None):\n    \"\"\"\n    copyto(dst, src, casting='same_kind', where=True)\n\n    Copies values from one array to another, broadcasting as necessary.\n\n    Raises a TypeError if the `casting` rule is violated, and if\n    `where` is provided, it selects which elements to copy.\n\n    .. versionadded:: 1.7.0\n\n    Parameters\n    ----------\n    dst : ndarray\n        The array into which values are copied.\n    src : array_like\n        The array from which values are copied.\n    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n        Controls what kind of data casting may occur when copying.\n\n          * 'no' means the data types should not be cast at all.\n          * 'equiv' means only byte-order changes are allowed.\n          * 'safe' means only casts which can preserve values are allowed.\n          * 'same_kind' means only safe casts or casts within a kind,\n            like float64 to float32, are allowed.\n          * 'unsafe' means any data conversions may be done.\n    where : array_like of bool, optional\n        A boolean array which is broadcasted to match the dimensions\n        of `dst`, and selects elements to copy from `src` to `dst`\n        wherever it contains the value True.\n\n    Examples\n    --------\n    >>> A = np.array([4, 5, 6])\n    >>> B = [1, 2, 3]\n    >>> np.copyto(A, B)\n    >>> A\n    array([1, 2, 3])\n\n    >>> A = np.array([[1, 2, 3], [4, 5, 6]])\n    >>> B = [[4, 5, 6], [7, 8, 9]]\n    >>> np.copyto(A, B)\n    >>> A\n    array([[4, 5, 6],\n           [7, 8, 9]])\n\n    \"\"\"\n    return (dst, src, where)"}, {"module": "numpy._core.multiarray", "name": "putmask", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "mask", "datatype": null}, {"name": "values", "datatype": null}], "source_code": "def putmask(a, /, mask, values):\n    \"\"\"\n    putmask(a, mask, values)\n\n    Changes elements of an array based on conditional and input values.\n\n    Sets ``a.flat[n] = values[n]`` for each n where ``mask.flat[n]==True``.\n\n    If `values` is not the same size as `a` and `mask` then it will repeat.\n    This gives behavior different from ``a[mask] = values``.\n\n    Parameters\n    ----------\n    a : ndarray\n        Target array.\n    mask : array_like\n        Boolean mask array. It has to be the same shape as `a`.\n    values : array_like\n        Values to put into `a` where `mask` is True. If `values` is smaller\n        than `a` it will be repeated.\n\n    See Also\n    --------\n    place, put, take, copyto\n\n    Examples\n    --------\n    >>> x = np.arange(6).reshape(2, 3)\n    >>> np.putmask(x, x>2, x**2)\n    >>> x\n    array([[ 0,  1,  2],\n           [ 9, 16, 25]])\n\n    If `values` is smaller than `a` it is repeated:\n\n    >>> x = np.arange(5)\n    >>> np.putmask(x, x>1, [-33, -44])\n    >>> x\n    array([  0,   1, -33, -44, -33])\n\n    \"\"\"\n    return (a, mask, values)"}, {"module": "numpy._core.multiarray", "name": "packbits", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "a", "datatype": null}, {"name": "axis", "datatype": null}, {"name": "bitorder", "datatype": null}], "source_code": "def packbits(a, axis=None, bitorder='big'):\n    \"\"\"\n    packbits(a, /, axis=None, bitorder='big')\n\n    Packs the elements of a binary-valued array into bits in a uint8 array.\n\n    The result is padded to full bytes by inserting zero bits at the end.\n\n    Parameters\n    ----------\n    a : array_like\n        An array of integers or booleans whose elements should be packed to\n        bits.\n    axis : int, optional\n        The dimension over which bit-packing is done.\n        ``None`` implies packing the flattened array.\n    bitorder : {'big', 'little'}, optional\n        The order of the input bits. 'big' will mimic bin(val),\n        ``[0, 0, 0, 0, 0, 0, 1, 1] => 3 = 0b00000011``, 'little' will\n        reverse the order so ``[1, 1, 0, 0, 0, 0, 0, 0] => 3``.\n        Defaults to 'big'.\n\n        .. versionadded:: 1.17.0\n\n    Returns\n    -------\n    packed : ndarray\n        Array of type uint8 whose elements represent bits corresponding to the\n        logical (0 or nonzero) value of the input elements. The shape of\n        `packed` has the same number of dimensions as the input (unless `axis`\n        is None, in which case the output is 1-D).\n\n    See Also\n    --------\n    unpackbits: Unpacks elements of a uint8 array into a binary-valued output\n                array.\n\n    Examples\n    --------\n    >>> a = np.array([[[1,0,1],\n    ...                [0,1,0]],\n    ...               [[1,1,0],\n    ...                [0,0,1]]])\n    >>> b = np.packbits(a, axis=-1)\n    >>> b\n    array([[[160],\n            [ 64]],\n           [[192],\n            [ 32]]], dtype=uint8)\n\n    Note that in binary 160 = 1010 0000, 64 = 0100 0000, 192 = 1100 0000,\n    and 32 = 0010 0000.\n\n    \"\"\"\n    return (a,)"}, {"module": "numpy._core.multiarray", "name": "unpackbits", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "a", "datatype": null}, {"name": "axis", "datatype": null}, {"name": "count", "datatype": null}, {"name": "bitorder", "datatype": null}], "source_code": "def unpackbits(a, axis=None, count=None, bitorder='big'):\n    \"\"\"\n    unpackbits(a, /, axis=None, count=None, bitorder='big')\n\n    Unpacks elements of a uint8 array into a binary-valued output array.\n\n    Each element of `a` represents a bit-field that should be unpacked\n    into a binary-valued output array. The shape of the output array is\n    either 1-D (if `axis` is ``None``) or the same shape as the input\n    array with unpacking done along the axis specified.\n\n    Parameters\n    ----------\n    a : ndarray, uint8 type\n       Input array.\n    axis : int, optional\n        The dimension over which bit-unpacking is done.\n        ``None`` implies unpacking the flattened array.\n    count : int or None, optional\n        The number of elements to unpack along `axis`, provided as a way\n        of undoing the effect of packing a size that is not a multiple\n        of eight. A non-negative number means to only unpack `count`\n        bits. A negative number means to trim off that many bits from\n        the end. ``None`` means to unpack the entire array (the\n        default). Counts larger than the available number of bits will\n        add zero padding to the output. Negative counts must not\n        exceed the available number of bits.\n\n        .. versionadded:: 1.17.0\n\n    bitorder : {'big', 'little'}, optional\n        The order of the returned bits. 'big' will mimic bin(val),\n        ``3 = 0b00000011 => [0, 0, 0, 0, 0, 0, 1, 1]``, 'little' will reverse\n        the order to ``[1, 1, 0, 0, 0, 0, 0, 0]``.\n        Defaults to 'big'.\n\n        .. versionadded:: 1.17.0\n\n    Returns\n    -------\n    unpacked : ndarray, uint8 type\n       The elements are binary-valued (0 or 1).\n\n    See Also\n    --------\n    packbits : Packs the elements of a binary-valued array into bits in\n               a uint8 array.\n\n    Examples\n    --------\n    >>> a = np.array([[2], [7], [23]], dtype=np.uint8)\n    >>> a\n    array([[ 2],\n           [ 7],\n           [23]], dtype=uint8)\n    >>> b = np.unpackbits(a, axis=1)\n    >>> b\n    array([[0, 0, 0, 0, 0, 0, 1, 0],\n           [0, 0, 0, 0, 0, 1, 1, 1],\n           [0, 0, 0, 1, 0, 1, 1, 1]], dtype=uint8)\n    >>> c = np.unpackbits(a, axis=1, count=-3)\n    >>> c\n    array([[0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0],\n           [0, 0, 0, 1, 0]], dtype=uint8)\n\n    >>> p = np.packbits(b, axis=0)\n    >>> np.unpackbits(p, axis=0)\n    array([[0, 0, 0, 0, 0, 0, 1, 0],\n           [0, 0, 0, 0, 0, 1, 1, 1],\n           [0, 0, 0, 1, 0, 1, 1, 1],\n           [0, 0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)\n    >>> np.array_equal(b, np.unpackbits(p, axis=0, count=b.shape[0]))\n    True\n\n    \"\"\"\n    return (a,)"}, {"module": "numpy._core.multiarray", "name": "shares_memory", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "a", "datatype": null}, {"name": "b", "datatype": null}, {"name": "max_work", "datatype": null}], "source_code": "def shares_memory(a, b, max_work=None):\n    \"\"\"\n    shares_memory(a, b, /, max_work=None)\n\n    Determine if two arrays share memory.\n\n    .. warning::\n\n       This function can be exponentially slow for some inputs, unless\n       `max_work` is set to a finite number or ``MAY_SHARE_BOUNDS``.\n       If in doubt, use `numpy.may_share_memory` instead.\n\n    Parameters\n    ----------\n    a, b : ndarray\n        Input arrays\n    max_work : int, optional\n        Effort to spend on solving the overlap problem (maximum number\n        of candidate solutions to consider). The following special\n        values are recognized:\n\n        max_work=MAY_SHARE_EXACT  (default)\n            The problem is solved exactly. In this case, the function returns\n            True only if there is an element shared between the arrays. Finding\n            the exact solution may take extremely long in some cases.\n        max_work=MAY_SHARE_BOUNDS\n            Only the memory bounds of a and b are checked.\n\n    Raises\n    ------\n    numpy.exceptions.TooHardError\n        Exceeded max_work.\n\n    Returns\n    -------\n    out : bool\n\n    See Also\n    --------\n    may_share_memory\n\n    Examples\n    --------\n    >>> x = np.array([1, 2, 3, 4])\n    >>> np.shares_memory(x, np.array([5, 6, 7]))\n    False\n    >>> np.shares_memory(x[::2], x)\n    True\n    >>> np.shares_memory(x[::2], x[1::2])\n    False\n\n    Checking whether two arrays share memory is NP-complete, and\n    runtime may increase exponentially in the number of\n    dimensions. Hence, `max_work` should generally be set to a finite\n    number, as it is possible to construct examples that take\n    extremely long to run:\n\n    >>> from numpy.lib.stride_tricks import as_strided\n    >>> x = np.zeros([192163377], dtype=np.int8)\n    >>> x1 = as_strided(x, strides=(36674, 61119, 85569), shape=(1049, 1049, 1049))\n    >>> x2 = as_strided(x[64023025:], strides=(12223, 12224, 1), shape=(1049, 1049, 1))\n    >>> np.shares_memory(x1, x2, max_work=1000)\n    Traceback (most recent call last):\n    ...\n    numpy.exceptions.TooHardError: Exceeded max_work\n\n    Running ``np.shares_memory(x1, x2)`` without `max_work` set takes\n    around 1 minute for this case. It is possible to find problems\n    that take still significantly longer.\n\n    \"\"\"\n    return (a, b)"}, {"module": "numpy._core.multiarray", "name": "may_share_memory", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "a", "datatype": null}, {"name": "b", "datatype": null}, {"name": "max_work", "datatype": null}], "source_code": "def may_share_memory(a, b, max_work=None):\n    \"\"\"\n    may_share_memory(a, b, /, max_work=None)\n\n    Determine if two arrays might share memory\n\n    A return of True does not necessarily mean that the two arrays\n    share any element.  It just means that they *might*.\n\n    Only the memory bounds of a and b are checked by default.\n\n    Parameters\n    ----------\n    a, b : ndarray\n        Input arrays\n    max_work : int, optional\n        Effort to spend on solving the overlap problem.  See\n        `shares_memory` for details.  Default for ``may_share_memory``\n        is to do a bounds check.\n\n    Returns\n    -------\n    out : bool\n\n    See Also\n    --------\n    shares_memory\n\n    Examples\n    --------\n    >>> np.may_share_memory(np.array([1,2]), np.array([5,8,9]))\n    False\n    >>> x = np.zeros([3, 4])\n    >>> np.may_share_memory(x[:,0], x[:,1])\n    True\n\n    \"\"\"\n    return (a, b)"}, {"module": "numpy._core.multiarray", "name": "is_busday", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "dates", "datatype": null}, {"name": "weekmask", "datatype": null}, {"name": "holidays", "datatype": null}, {"name": "busdaycal", "datatype": null}, {"name": "out", "datatype": null}], "source_code": "def is_busday(dates, weekmask=None, holidays=None, busdaycal=None, out=None):\n    \"\"\"\n    is_busday(dates, weekmask='1111100', holidays=None, busdaycal=None, out=None)\n\n    Calculates which of the given dates are valid days, and which are not.\n\n    .. versionadded:: 1.7.0\n\n    Parameters\n    ----------\n    dates : array_like of datetime64[D]\n        The array of dates to process.\n    weekmask : str or array_like of bool, optional\n        A seven-element array indicating which of Monday through Sunday are\n        valid days. May be specified as a length-seven list or array, like\n        [1,1,1,1,1,0,0]; a length-seven string, like '1111100'; or a string\n        like \"Mon Tue Wed Thu Fri\", made up of 3-character abbreviations for\n        weekdays, optionally separated by white space. Valid abbreviations\n        are: Mon Tue Wed Thu Fri Sat Sun\n    holidays : array_like of datetime64[D], optional\n        An array of dates to consider as invalid dates.  They may be\n        specified in any order, and NaT (not-a-time) dates are ignored.\n        This list is saved in a normalized form that is suited for\n        fast calculations of valid days.\n    busdaycal : busdaycalendar, optional\n        A `busdaycalendar` object which specifies the valid days. If this\n        parameter is provided, neither weekmask nor holidays may be\n        provided.\n    out : array of bool, optional\n        If provided, this array is filled with the result.\n\n    Returns\n    -------\n    out : array of bool\n        An array with the same shape as ``dates``, containing True for\n        each valid day, and False for each invalid day.\n\n    See Also\n    --------\n    busdaycalendar : An object that specifies a custom set of valid days.\n    busday_offset : Applies an offset counted in valid days.\n    busday_count : Counts how many valid days are in a half-open date range.\n\n    Examples\n    --------\n    >>> # The weekdays are Friday, Saturday, and Monday\n    ... np.is_busday(['2011-07-01', '2011-07-02', '2011-07-18'],\n    ...                 holidays=['2011-07-01', '2011-07-04', '2011-07-17'])\n    array([False, False,  True])\n    \"\"\"\n    return (dates, weekmask, holidays, out)"}, {"module": "numpy._core.multiarray", "name": "busday_offset", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "dates", "datatype": null}, {"name": "offsets", "datatype": null}, {"name": "roll", "datatype": null}, {"name": "weekmask", "datatype": null}, {"name": "holidays", "datatype": null}, {"name": "busdaycal", "datatype": null}, {"name": "out", "datatype": null}], "source_code": "def busday_offset(dates, offsets, roll=None, weekmask=None, holidays=None,\n                  busdaycal=None, out=None):\n    \"\"\"\n    busday_offset(dates, offsets, roll='raise', weekmask='1111100', holidays=None, busdaycal=None, out=None)\n\n    First adjusts the date to fall on a valid day according to\n    the ``roll`` rule, then applies offsets to the given dates\n    counted in valid days.\n\n    .. versionadded:: 1.7.0\n\n    Parameters\n    ----------\n    dates : array_like of datetime64[D]\n        The array of dates to process.\n    offsets : array_like of int\n        The array of offsets, which is broadcast with ``dates``.\n    roll : {'raise', 'nat', 'forward', 'following', 'backward', 'preceding', 'modifiedfollowing', 'modifiedpreceding'}, optional\n        How to treat dates that do not fall on a valid day. The default\n        is 'raise'.\n\n          * 'raise' means to raise an exception for an invalid day.\n          * 'nat' means to return a NaT (not-a-time) for an invalid day.\n          * 'forward' and 'following' mean to take the first valid day\n            later in time.\n          * 'backward' and 'preceding' mean to take the first valid day\n            earlier in time.\n          * 'modifiedfollowing' means to take the first valid day\n            later in time unless it is across a Month boundary, in which\n            case to take the first valid day earlier in time.\n          * 'modifiedpreceding' means to take the first valid day\n            earlier in time unless it is across a Month boundary, in which\n            case to take the first valid day later in time.\n    weekmask : str or array_like of bool, optional\n        A seven-element array indicating which of Monday through Sunday are\n        valid days. May be specified as a length-seven list or array, like\n        [1,1,1,1,1,0,0]; a length-seven string, like '1111100'; or a string\n        like \"Mon Tue Wed Thu Fri\", made up of 3-character abbreviations for\n        weekdays, optionally separated by white space. Valid abbreviations\n        are: Mon Tue Wed Thu Fri Sat Sun\n    holidays : array_like of datetime64[D], optional\n        An array of dates to consider as invalid dates.  They may be\n        specified in any order, and NaT (not-a-time) dates are ignored.\n        This list is saved in a normalized form that is suited for\n        fast calculations of valid days.\n    busdaycal : busdaycalendar, optional\n        A `busdaycalendar` object which specifies the valid days. If this\n        parameter is provided, neither weekmask nor holidays may be\n        provided.\n    out : array of datetime64[D], optional\n        If provided, this array is filled with the result.\n\n    Returns\n    -------\n    out : array of datetime64[D]\n        An array with a shape from broadcasting ``dates`` and ``offsets``\n        together, containing the dates with offsets applied.\n\n    See Also\n    --------\n    busdaycalendar : An object that specifies a custom set of valid days.\n    is_busday : Returns a boolean array indicating valid days.\n    busday_count : Counts how many valid days are in a half-open date range.\n\n    Examples\n    --------\n    >>> # First business day in October 2011 (not accounting for holidays)\n    ... np.busday_offset('2011-10', 0, roll='forward')\n    numpy.datetime64('2011-10-03')\n    >>> # Last business day in February 2012 (not accounting for holidays)\n    ... np.busday_offset('2012-03', -1, roll='forward')\n    numpy.datetime64('2012-02-29')\n    >>> # Third Wednesday in January 2011\n    ... np.busday_offset('2011-01', 2, roll='forward', weekmask='Wed')\n    numpy.datetime64('2011-01-19')\n    >>> # 2012 Mother's Day in Canada and the U.S.\n    ... np.busday_offset('2012-05', 1, roll='forward', weekmask='Sun')\n    numpy.datetime64('2012-05-13')\n\n    >>> # First business day on or after a date\n    ... np.busday_offset('2011-03-20', 0, roll='forward')\n    numpy.datetime64('2011-03-21')\n    >>> np.busday_offset('2011-03-22', 0, roll='forward')\n    numpy.datetime64('2011-03-22')\n    >>> # First business day after a date\n    ... np.busday_offset('2011-03-20', 1, roll='backward')\n    numpy.datetime64('2011-03-21')\n    >>> np.busday_offset('2011-03-22', 1, roll='backward')\n    numpy.datetime64('2011-03-23')\n    \"\"\"\n    return (dates, offsets, weekmask, holidays, out)"}, {"module": "numpy._core.multiarray", "name": "busday_count", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "begindates", "datatype": null}, {"name": "enddates", "datatype": null}, {"name": "weekmask", "datatype": null}, {"name": "holidays", "datatype": null}, {"name": "busdaycal", "datatype": null}, {"name": "out", "datatype": null}], "source_code": "def busday_count(begindates, enddates, weekmask=None, holidays=None,\n                 busdaycal=None, out=None):\n    \"\"\"\n    busday_count(begindates, enddates, weekmask='1111100', holidays=[], busdaycal=None, out=None)\n\n    Counts the number of valid days between `begindates` and\n    `enddates`, not including the day of `enddates`.\n\n    If ``enddates`` specifies a date value that is earlier than the\n    corresponding ``begindates`` date value, the count will be negative.\n\n    .. versionadded:: 1.7.0\n\n    Parameters\n    ----------\n    begindates : array_like of datetime64[D]\n        The array of the first dates for counting.\n    enddates : array_like of datetime64[D]\n        The array of the end dates for counting, which are excluded\n        from the count themselves.\n    weekmask : str or array_like of bool, optional\n        A seven-element array indicating which of Monday through Sunday are\n        valid days. May be specified as a length-seven list or array, like\n        [1,1,1,1,1,0,0]; a length-seven string, like '1111100'; or a string\n        like \"Mon Tue Wed Thu Fri\", made up of 3-character abbreviations for\n        weekdays, optionally separated by white space. Valid abbreviations\n        are: Mon Tue Wed Thu Fri Sat Sun\n    holidays : array_like of datetime64[D], optional\n        An array of dates to consider as invalid dates.  They may be\n        specified in any order, and NaT (not-a-time) dates are ignored.\n        This list is saved in a normalized form that is suited for\n        fast calculations of valid days.\n    busdaycal : busdaycalendar, optional\n        A `busdaycalendar` object which specifies the valid days. If this\n        parameter is provided, neither weekmask nor holidays may be\n        provided.\n    out : array of int, optional\n        If provided, this array is filled with the result.\n\n    Returns\n    -------\n    out : array of int\n        An array with a shape from broadcasting ``begindates`` and ``enddates``\n        together, containing the number of valid days between\n        the begin and end dates.\n\n    See Also\n    --------\n    busdaycalendar : An object that specifies a custom set of valid days.\n    is_busday : Returns a boolean array indicating valid days.\n    busday_offset : Applies an offset counted in valid days.\n\n    Examples\n    --------\n    >>> # Number of weekdays in January 2011\n    ... np.busday_count('2011-01', '2011-02')\n    21\n    >>> # Number of weekdays in 2011\n    >>> np.busday_count('2011', '2012')\n    260\n    >>> # Number of Saturdays in 2011\n    ... np.busday_count('2011', '2012', weekmask='Sat')\n    53\n    \"\"\"\n    return (begindates, enddates, weekmask, holidays, out)"}, {"module": "numpy._core.multiarray", "name": "datetime_as_string", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "arr", "datatype": null}, {"name": "unit", "datatype": null}, {"name": "timezone", "datatype": null}, {"name": "casting", "datatype": null}], "source_code": "def datetime_as_string(arr, unit=None, timezone=None, casting=None):\n    \"\"\"\n    datetime_as_string(arr, unit=None, timezone='naive', casting='same_kind')\n\n    Convert an array of datetimes into an array of strings.\n\n    Parameters\n    ----------\n    arr : array_like of datetime64\n        The array of UTC timestamps to format.\n    unit : str\n        One of None, 'auto', or a :ref:`datetime unit <arrays.dtypes.dateunits>`.\n    timezone : {'naive', 'UTC', 'local'} or tzinfo\n        Timezone information to use when displaying the datetime. If 'UTC', end\n        with a Z to indicate UTC time. If 'local', convert to the local timezone\n        first, and suffix with a +-#### timezone offset. If a tzinfo object,\n        then do as with 'local', but use the specified timezone.\n    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}\n        Casting to allow when changing between datetime units.\n\n    Returns\n    -------\n    str_arr : ndarray\n        An array of strings the same shape as `arr`.\n\n    Examples\n    --------\n    >>> import pytz\n    >>> d = np.arange('2002-10-27T04:30', 4*60, 60, dtype='M8[m]')\n    >>> d\n    array(['2002-10-27T04:30', '2002-10-27T05:30', '2002-10-27T06:30',\n           '2002-10-27T07:30'], dtype='datetime64[m]')\n\n    Setting the timezone to UTC shows the same information, but with a Z suffix\n\n    >>> np.datetime_as_string(d, timezone='UTC')\n    array(['2002-10-27T04:30Z', '2002-10-27T05:30Z', '2002-10-27T06:30Z',\n           '2002-10-27T07:30Z'], dtype='<U35')\n\n    Note that we picked datetimes that cross a DST boundary. Passing in a\n    ``pytz`` timezone object will print the appropriate offset\n\n    >>> np.datetime_as_string(d, timezone=pytz.timezone('US/Eastern'))\n    array(['2002-10-27T00:30-0400', '2002-10-27T01:30-0400',\n           '2002-10-27T01:30-0500', '2002-10-27T02:30-0500'], dtype='<U39')\n\n    Passing in a unit will change the precision\n\n    >>> np.datetime_as_string(d, unit='h')\n    array(['2002-10-27T04', '2002-10-27T05', '2002-10-27T06', '2002-10-27T07'],\n          dtype='<U32')\n    >>> np.datetime_as_string(d, unit='s')\n    array(['2002-10-27T04:30:00', '2002-10-27T05:30:00', '2002-10-27T06:30:00',\n           '2002-10-27T07:30:00'], dtype='<U38')\n\n    'casting' can be used to specify whether precision can be changed\n\n    >>> np.datetime_as_string(d, unit='h', casting='safe')\n    Traceback (most recent call last):\n        ...\n    TypeError: Cannot create a datetime string as units 'h' from a NumPy\n    datetime with units 'm' according to the rule 'safe'\n    \"\"\"\n    return (arr,)"}, {"module": "numpy._typing.setup", "name": "configuration", "dependend_class": null, "function_calls": ["Configuration", "config.add_data_files"], "arguments": [{"name": "parent_package", "datatype": null}, {"name": "top_path", "datatype": null}], "source_code": "def configuration(parent_package='', top_path=None):\n    from numpy.distutils.misc_util import Configuration\n    config = Configuration('_typing', parent_package, top_path)\n    config.add_data_files('*.pyi')\n    return config"}, {"module": "numpy.compat.setup", "name": "configuration", "dependend_class": null, "function_calls": ["Configuration", "config.add_subpackage"], "arguments": [{"name": "parent_package", "datatype": null}, {"name": "top_path", "datatype": null}], "source_code": "def configuration(parent_package='',top_path=None):\n    from numpy.distutils.misc_util import Configuration\n\n    config = Configuration('compat', parent_package, top_path)\n    config.add_subpackage('tests')\n    return config"}, {"module": "numpy.compat.tests.test_compat", "name": "test_isfileobj", "dependend_class": null, "function_calls": ["tempdir", "join", "assert_", "assert_", "assert_", "assert_", "isfileobj", "isfileobj", "isfileobj", "isfileobj", "BufferedReader", "BytesIO"], "arguments": [], "source_code": "def test_isfileobj():\n    with tempdir(prefix=\"numpy_test_compat_\") as folder:\n        filename = join(folder, 'a.bin')\n\n        with open(filename, 'wb') as f:\n            assert_(isfileobj(f))\n\n        with open(filename, 'ab') as f:\n            assert_(isfileobj(f))\n\n        with open(filename, 'rb') as f:\n            assert_(isfileobj(f))\n\n        assert_(isfileobj(BufferedReader(BytesIO())) is False)"}, {"module": "numpy.core.multiarray", "name": "empty_like", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "prototype", "datatype": null}, {"name": "dtype", "datatype": null}, {"name": "order", "datatype": null}, {"name": "subok", "datatype": null}, {"name": "shape", "datatype": null}], "source_code": "def empty_like(prototype, dtype=None, order=None, subok=None, shape=None):\n    \"\"\"\n    empty_like(prototype, dtype=None, order='K', subok=True, shape=None)\n\n    Return a new array with the same shape and type as a given array.\n\n    Parameters\n    ----------\n    prototype : array_like\n        The shape and data-type of `prototype` define these same attributes\n        of the returned array.\n    dtype : data-type, optional\n        Overrides the data type of the result.\n\n        .. versionadded:: 1.6.0\n    order : {'C', 'F', 'A', or 'K'}, optional\n        Overrides the memory layout of the result. 'C' means C-order,\n        'F' means F-order, 'A' means 'F' if `prototype` is Fortran\n        contiguous, 'C' otherwise. 'K' means match the layout of `prototype`\n        as closely as possible.\n\n        .. versionadded:: 1.6.0\n    subok : bool, optional.\n        If True, then the newly created array will use the sub-class\n        type of `prototype`, otherwise it will be a base-class array. Defaults\n        to True.\n    shape : int or sequence of ints, optional.\n        Overrides the shape of the result. If order='K' and the number of\n        dimensions is unchanged, will try to keep order, otherwise,\n        order='C' is implied.\n\n        .. versionadded:: 1.17.0\n\n    Returns\n    -------\n    out : ndarray\n        Array of uninitialized (arbitrary) data with the same\n        shape and type as `prototype`.\n\n    See Also\n    --------\n    ones_like : Return an array of ones with shape and type of input.\n    zeros_like : Return an array of zeros with shape and type of input.\n    full_like : Return a new array with shape of input filled with value.\n    empty : Return a new uninitialized array.\n\n    Notes\n    -----\n    This function does *not* initialize the returned array; to do that use\n    `zeros_like` or `ones_like` instead.  It may be marginally faster than\n    the functions that do set the array values.\n\n    Examples\n    --------\n    >>> a = ([1,2,3], [4,5,6])                         # a is array-like\n    >>> np.empty_like(a)\n    array([[-1073741821, -1073741821,           3],    # uninitialized\n           [          0,           0, -1073741821]])\n    >>> a = np.array([[1., 2., 3.],[4.,5.,6.]])\n    >>> np.empty_like(a)\n    array([[ -2.00000715e+000,   1.48219694e-323,  -2.00000572e+000], # uninitialized\n           [  4.38791518e-305,  -2.00000715e+000,   4.17269252e-309]])\n\n    \"\"\"\n    return (prototype,)"}, {"module": "numpy.core.multiarray", "name": "concatenate", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher", "arrays.append"], "arguments": [{"name": "arrays", "datatype": null}, {"name": "axis", "datatype": null}, {"name": "out", "datatype": null}], "source_code": "def concatenate(arrays, axis=None, out=None, *, dtype=None, casting=None):\n    \"\"\"\n    concatenate((a1, a2, ...), axis=0, out=None, dtype=None, casting=\"same_kind\")\n\n    Join a sequence of arrays along an existing axis.\n\n    Parameters\n    ----------\n    a1, a2, ... : sequence of array_like\n        The arrays must have the same shape, except in the dimension\n        corresponding to `axis` (the first, by default).\n    axis : int, optional\n        The axis along which the arrays will be joined.  If axis is None,\n        arrays are flattened before use.  Default is 0.\n    out : ndarray, optional\n        If provided, the destination to place the result. The shape must be\n        correct, matching that of what concatenate would have returned if no\n        out argument were specified.\n    dtype : str or dtype\n        If provided, the destination array will have this dtype. Cannot be\n        provided together with `out`.\n\n        .. versionadded:: 1.20.0\n\n    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n        Controls what kind of data casting may occur. Defaults to 'same_kind'.\n\n        .. versionadded:: 1.20.0\n\n    Returns\n    -------\n    res : ndarray\n        The concatenated array.\n\n    See Also\n    --------\n    ma.concatenate : Concatenate function that preserves input masks.\n    array_split : Split an array into multiple sub-arrays of equal or\n                  near-equal size.\n    split : Split array into a list of multiple sub-arrays of equal size.\n    hsplit : Split array into multiple sub-arrays horizontally (column wise).\n    vsplit : Split array into multiple sub-arrays vertically (row wise).\n    dsplit : Split array into multiple sub-arrays along the 3rd axis (depth).\n    stack : Stack a sequence of arrays along a new axis.\n    block : Assemble arrays from blocks.\n    hstack : Stack arrays in sequence horizontally (column wise).\n    vstack : Stack arrays in sequence vertically (row wise).\n    dstack : Stack arrays in sequence depth wise (along third dimension).\n    column_stack : Stack 1-D arrays as columns into a 2-D array.\n\n    Notes\n    -----\n    When one or more of the arrays to be concatenated is a MaskedArray,\n    this function will return a MaskedArray object instead of an ndarray,\n    but the input masks are *not* preserved. In cases where a MaskedArray\n    is expected as input, use the ma.concatenate function from the masked\n    array module instead.\n\n    Examples\n    --------\n    >>> a = np.array([[1, 2], [3, 4]])\n    >>> b = np.array([[5, 6]])\n    >>> np.concatenate((a, b), axis=0)\n    array([[1, 2],\n           [3, 4],\n           [5, 6]])\n    >>> np.concatenate((a, b.T), axis=1)\n    array([[1, 2, 5],\n           [3, 4, 6]])\n    >>> np.concatenate((a, b), axis=None)\n    array([1, 2, 3, 4, 5, 6])\n\n    This function will not preserve masking of MaskedArray inputs.\n\n    >>> a = np.ma.arange(3)\n    >>> a[1] = np.ma.masked\n    >>> b = np.arange(2, 5)\n    >>> a\n    masked_array(data=[0, --, 2],\n                 mask=[False,  True, False],\n           fill_value=999999)\n    >>> b\n    array([2, 3, 4])\n    >>> np.concatenate([a, b])\n    masked_array(data=[0, 1, 2, 2, 3, 4],\n                 mask=False,\n           fill_value=999999)\n    >>> np.ma.concatenate([a, b])\n    masked_array(data=[0, --, 2, 2, 3, 4],\n                 mask=[False,  True, False, False, False, False],\n           fill_value=999999)\n\n    \"\"\"\n    if out is not None:\n        # optimize for the typical case where only arrays is provided\n        arrays = list(arrays)\n        arrays.append(out)\n    return arrays"}, {"module": "numpy.core.multiarray", "name": "inner", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "a", "datatype": null}, {"name": "b", "datatype": null}], "source_code": "def inner(a, b):\n    \"\"\"\n    inner(a, b, /)\n\n    Inner product of two arrays.\n\n    Ordinary inner product of vectors for 1-D arrays (without complex\n    conjugation), in higher dimensions a sum product over the last axes.\n\n    Parameters\n    ----------\n    a, b : array_like\n        If `a` and `b` are nonscalar, their last dimensions must match.\n\n    Returns\n    -------\n    out : ndarray\n        If `a` and `b` are both\n        scalars or both 1-D arrays then a scalar is returned; otherwise\n        an array is returned.\n        ``out.shape = (*a.shape[:-1], *b.shape[:-1])``\n\n    Raises\n    ------\n    ValueError\n        If both `a` and `b` are nonscalar and their last dimensions have\n        different sizes.\n\n    See Also\n    --------\n    tensordot : Sum products over arbitrary axes.\n    dot : Generalised matrix product, using second last dimension of `b`.\n    einsum : Einstein summation convention.\n\n    Notes\n    -----\n    For vectors (1-D arrays) it computes the ordinary inner-product::\n\n        np.inner(a, b) = sum(a[:]*b[:])\n\n    More generally, if ``ndim(a) = r > 0`` and ``ndim(b) = s > 0``::\n\n        np.inner(a, b) = np.tensordot(a, b, axes=(-1,-1))\n\n    or explicitly::\n\n        np.inner(a, b)[i0,...,ir-2,j0,...,js-2]\n             = sum(a[i0,...,ir-2,:]*b[j0,...,js-2,:])\n\n    In addition `a` or `b` may be scalars, in which case::\n\n       np.inner(a,b) = a*b\n\n    Examples\n    --------\n    Ordinary inner product for vectors:\n\n    >>> a = np.array([1,2,3])\n    >>> b = np.array([0,1,0])\n    >>> np.inner(a, b)\n    2\n\n    Some multidimensional examples:\n\n    >>> a = np.arange(24).reshape((2,3,4))\n    >>> b = np.arange(4)\n    >>> c = np.inner(a, b)\n    >>> c.shape\n    (2, 3)\n    >>> c\n    array([[ 14,  38,  62],\n           [ 86, 110, 134]])\n\n    >>> a = np.arange(2).reshape((1,1,2))\n    >>> b = np.arange(6).reshape((3,2))\n    >>> c = np.inner(a, b)\n    >>> c.shape\n    (1, 1, 3)\n    >>> c\n    array([[[1, 3, 5]]])\n\n    An example where `b` is a scalar:\n\n    >>> np.inner(np.eye(2), 7)\n    array([[7., 0.],\n           [0., 7.]])\n\n    \"\"\"\n    return (a, b)"}, {"module": "numpy.core.multiarray", "name": "where", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "condition", "datatype": null}, {"name": "x", "datatype": null}, {"name": "y", "datatype": null}], "source_code": "def where(condition, x=None, y=None):\n    \"\"\"\n    where(condition, [x, y], /)\n\n    Return elements chosen from `x` or `y` depending on `condition`.\n\n    .. note::\n        When only `condition` is provided, this function is a shorthand for\n        ``np.asarray(condition).nonzero()``. Using `nonzero` directly should be\n        preferred, as it behaves correctly for subclasses. The rest of this\n        documentation covers only the case where all three arguments are\n        provided.\n\n    Parameters\n    ----------\n    condition : array_like, bool\n        Where True, yield `x`, otherwise yield `y`.\n    x, y : array_like\n        Values from which to choose. `x`, `y` and `condition` need to be\n        broadcastable to some shape.\n\n    Returns\n    -------\n    out : ndarray\n        An array with elements from `x` where `condition` is True, and elements\n        from `y` elsewhere.\n\n    See Also\n    --------\n    choose\n    nonzero : The function that is called when x and y are omitted\n\n    Notes\n    -----\n    If all the arrays are 1-D, `where` is equivalent to::\n\n        [xv if c else yv\n         for c, xv, yv in zip(condition, x, y)]\n\n    Examples\n    --------\n    >>> a = np.arange(10)\n    >>> a\n    array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n    >>> np.where(a < 5, a, 10*a)\n    array([ 0,  1,  2,  3,  4, 50, 60, 70, 80, 90])\n\n    This can be used on multidimensional arrays too:\n\n    >>> np.where([[True, False], [True, True]],\n    ...          [[1, 2], [3, 4]],\n    ...          [[9, 8], [7, 6]])\n    array([[1, 8],\n           [3, 4]])\n\n    The shapes of x, y, and the condition are broadcast together:\n\n    >>> x, y = np.ogrid[:3, :4]\n    >>> np.where(x < y, x, 10 + y)  # both x and 10+y are broadcast\n    array([[10,  0,  0,  0],\n           [10, 11,  1,  1],\n           [10, 11, 12,  2]])\n\n    >>> a = np.array([[0, 1, 2],\n    ...               [0, 2, 4],\n    ...               [0, 3, 6]])\n    >>> np.where(a < 4, a, -1)  # -1 is broadcast\n    array([[ 0,  1,  2],\n           [ 0,  2, -1],\n           [ 0,  3, -1]])\n    \"\"\"\n    return (condition, x, y)"}, {"module": "numpy.core.multiarray", "name": "lexsort", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "keys", "datatype": null}, {"name": "axis", "datatype": null}], "source_code": "def lexsort(keys, axis=None):\n    \"\"\"\n    lexsort(keys, axis=-1)\n\n    Perform an indirect stable sort using a sequence of keys.\n\n    Given multiple sorting keys, which can be interpreted as columns in a\n    spreadsheet, lexsort returns an array of integer indices that describes\n    the sort order by multiple columns. The last key in the sequence is used\n    for the primary sort order, the second-to-last key for the secondary sort\n    order, and so on. The keys argument must be a sequence of objects that\n    can be converted to arrays of the same shape. If a 2D array is provided\n    for the keys argument, its rows are interpreted as the sorting keys and\n    sorting is according to the last row, second last row etc.\n\n    Parameters\n    ----------\n    keys : (k, N) array or tuple containing k (N,)-shaped sequences\n        The `k` different \"columns\" to be sorted.  The last column (or row if\n        `keys` is a 2D array) is the primary sort key.\n    axis : int, optional\n        Axis to be indirectly sorted.  By default, sort over the last axis.\n\n    Returns\n    -------\n    indices : (N,) ndarray of ints\n        Array of indices that sort the keys along the specified axis.\n\n    See Also\n    --------\n    argsort : Indirect sort.\n    ndarray.sort : In-place sort.\n    sort : Return a sorted copy of an array.\n\n    Examples\n    --------\n    Sort names: first by surname, then by name.\n\n    >>> surnames =    ('Hertz',    'Galilei', 'Hertz')\n    >>> first_names = ('Heinrich', 'Galileo', 'Gustav')\n    >>> ind = np.lexsort((first_names, surnames))\n    >>> ind\n    array([1, 2, 0])\n\n    >>> [surnames[i] + \", \" + first_names[i] for i in ind]\n    ['Galilei, Galileo', 'Hertz, Gustav', 'Hertz, Heinrich']\n\n    Sort two columns of numbers:\n\n    >>> a = [1,5,1,4,3,4,4] # First column\n    >>> b = [9,4,0,4,0,2,1] # Second column\n    >>> ind = np.lexsort((b,a)) # Sort by a, then by b\n    >>> ind\n    array([2, 0, 4, 6, 5, 3, 1])\n\n    >>> [(a[i],b[i]) for i in ind]\n    [(1, 0), (1, 9), (3, 0), (4, 1), (4, 2), (4, 4), (5, 4)]\n\n    Note that sorting is first according to the elements of ``a``.\n    Secondary sorting is according to the elements of ``b``.\n\n    A normal ``argsort`` would have yielded:\n\n    >>> [(a[i],b[i]) for i in np.argsort(a)]\n    [(1, 9), (1, 0), (3, 0), (4, 4), (4, 2), (4, 1), (5, 4)]\n\n    Structured arrays are sorted lexically by ``argsort``:\n\n    >>> x = np.array([(1,9), (5,4), (1,0), (4,4), (3,0), (4,2), (4,1)],\n    ...              dtype=np.dtype([('x', int), ('y', int)]))\n\n    >>> np.argsort(x) # or np.argsort(x, order=('x', 'y'))\n    array([2, 0, 4, 6, 5, 3, 1])\n\n    \"\"\"\n    if isinstance(keys, tuple):\n        return keys\n    else:\n        return (keys,)"}, {"module": "numpy.core.multiarray", "name": "can_cast", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "from_", "datatype": null}, {"name": "to", "datatype": null}, {"name": "casting", "datatype": null}], "source_code": "def can_cast(from_, to, casting=None):\n    \"\"\"\n    can_cast(from_, to, casting='safe')\n\n    Returns True if cast between data types can occur according to the\n    casting rule.  If from is a scalar or array scalar, also returns\n    True if the scalar value can be cast without overflow or truncation\n    to an integer.\n\n    Parameters\n    ----------\n    from_ : dtype, dtype specifier, scalar, or array\n        Data type, scalar, or array to cast from.\n    to : dtype or dtype specifier\n        Data type to cast to.\n    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n        Controls what kind of data casting may occur.\n\n          * 'no' means the data types should not be cast at all.\n          * 'equiv' means only byte-order changes are allowed.\n          * 'safe' means only casts which can preserve values are allowed.\n          * 'same_kind' means only safe casts or casts within a kind,\n            like float64 to float32, are allowed.\n          * 'unsafe' means any data conversions may be done.\n\n    Returns\n    -------\n    out : bool\n        True if cast can occur according to the casting rule.\n\n    Notes\n    -----\n    .. versionchanged:: 1.17.0\n       Casting between a simple data type and a structured one is possible only\n       for \"unsafe\" casting.  Casting to multiple fields is allowed, but\n       casting from multiple fields is not.\n\n    .. versionchanged:: 1.9.0\n       Casting from numeric to string types in 'safe' casting mode requires\n       that the string dtype length is long enough to store the maximum\n       integer/float value converted.\n\n    See also\n    --------\n    dtype, result_type\n\n    Examples\n    --------\n    Basic examples\n\n    >>> np.can_cast(np.int32, np.int64)\n    True\n    >>> np.can_cast(np.float64, complex)\n    True\n    >>> np.can_cast(complex, float)\n    False\n\n    >>> np.can_cast('i8', 'f8')\n    True\n    >>> np.can_cast('i8', 'f4')\n    False\n    >>> np.can_cast('i4', 'S4')\n    False\n\n    Casting scalars\n\n    >>> np.can_cast(100, 'i1')\n    True\n    >>> np.can_cast(150, 'i1')\n    False\n    >>> np.can_cast(150, 'u1')\n    True\n\n    >>> np.can_cast(3.5e100, np.float32)\n    False\n    >>> np.can_cast(1000.0, np.float32)\n    True\n\n    Array scalar checks the value, array does not\n\n    >>> np.can_cast(np.array(1000.0), np.float32)\n    True\n    >>> np.can_cast(np.array([1000.0]), np.float32)\n    False\n\n    Using the casting rules\n\n    >>> np.can_cast('i8', 'i8', 'no')\n    True\n    >>> np.can_cast('<i8', '>i8', 'no')\n    False\n\n    >>> np.can_cast('<i8', '>i8', 'equiv')\n    True\n    >>> np.can_cast('<i4', '>i8', 'equiv')\n    False\n\n    >>> np.can_cast('<i4', '>i8', 'safe')\n    True\n    >>> np.can_cast('<i8', '>i4', 'safe')\n    False\n\n    >>> np.can_cast('<i8', '>i4', 'same_kind')\n    True\n    >>> np.can_cast('<i8', '>u4', 'same_kind')\n    False\n\n    >>> np.can_cast('<i8', '>u4', 'unsafe')\n    True\n\n    \"\"\"\n    return (from_,)"}, {"module": "numpy.core.multiarray", "name": "min_scalar_type", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "a", "datatype": null}], "source_code": "def min_scalar_type(a):\n    \"\"\"\n    min_scalar_type(a, /)\n\n    For scalar ``a``, returns the data type with the smallest size\n    and smallest scalar kind which can hold its value.  For non-scalar\n    array ``a``, returns the vector's dtype unmodified.\n\n    Floating point values are not demoted to integers,\n    and complex values are not demoted to floats.\n\n    Parameters\n    ----------\n    a : scalar or array_like\n        The value whose minimal data type is to be found.\n\n    Returns\n    -------\n    out : dtype\n        The minimal data type.\n\n    Notes\n    -----\n    .. versionadded:: 1.6.0\n\n    See Also\n    --------\n    result_type, promote_types, dtype, can_cast\n\n    Examples\n    --------\n    >>> np.min_scalar_type(10)\n    dtype('uint8')\n\n    >>> np.min_scalar_type(-260)\n    dtype('int16')\n\n    >>> np.min_scalar_type(3.1)\n    dtype('float16')\n\n    >>> np.min_scalar_type(1e50)\n    dtype('float64')\n\n    >>> np.min_scalar_type(np.arange(4,dtype='f8'))\n    dtype('float64')\n\n    \"\"\"\n    return (a,)"}, {"module": "numpy.core.multiarray", "name": "result_type", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [], "source_code": "def result_type(*arrays_and_dtypes):\n    \"\"\"\n    result_type(*arrays_and_dtypes)\n\n    Returns the type that results from applying the NumPy\n    type promotion rules to the arguments.\n\n    Type promotion in NumPy works similarly to the rules in languages\n    like C++, with some slight differences.  When both scalars and\n    arrays are used, the array's type takes precedence and the actual value\n    of the scalar is taken into account.\n\n    For example, calculating 3*a, where a is an array of 32-bit floats,\n    intuitively should result in a 32-bit float output.  If the 3 is a\n    32-bit integer, the NumPy rules indicate it can't convert losslessly\n    into a 32-bit float, so a 64-bit float should be the result type.\n    By examining the value of the constant, '3', we see that it fits in\n    an 8-bit integer, which can be cast losslessly into the 32-bit float.\n\n    Parameters\n    ----------\n    arrays_and_dtypes : list of arrays and dtypes\n        The operands of some operation whose result type is needed.\n\n    Returns\n    -------\n    out : dtype\n        The result type.\n\n    See also\n    --------\n    dtype, promote_types, min_scalar_type, can_cast\n\n    Notes\n    -----\n    .. versionadded:: 1.6.0\n\n    The specific algorithm used is as follows.\n\n    Categories are determined by first checking which of boolean,\n    integer (int/uint), or floating point (float/complex) the maximum\n    kind of all the arrays and the scalars are.\n\n    If there are only scalars or the maximum category of the scalars\n    is higher than the maximum category of the arrays,\n    the data types are combined with :func:`promote_types`\n    to produce the return value.\n\n    Otherwise, `min_scalar_type` is called on each scalar, and\n    the resulting data types are all combined with :func:`promote_types`\n    to produce the return value.\n\n    The set of int values is not a subset of the uint values for types\n    with the same number of bits, something not reflected in\n    :func:`min_scalar_type`, but handled as a special case in `result_type`.\n\n    Examples\n    --------\n    >>> np.result_type(3, np.arange(7, dtype='i1'))\n    dtype('int8')\n\n    >>> np.result_type('i4', 'c8')\n    dtype('complex128')\n\n    >>> np.result_type(3.0, -2)\n    dtype('float64')\n\n    \"\"\"\n    return arrays_and_dtypes"}, {"module": "numpy.core.multiarray", "name": "dot", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "a", "datatype": null}, {"name": "b", "datatype": null}, {"name": "out", "datatype": null}], "source_code": "def dot(a, b, out=None):\n    \"\"\"\n    dot(a, b, out=None)\n\n    Dot product of two arrays. Specifically,\n\n    - If both `a` and `b` are 1-D arrays, it is inner product of vectors\n      (without complex conjugation).\n\n    - If both `a` and `b` are 2-D arrays, it is matrix multiplication,\n      but using :func:`matmul` or ``a @ b`` is preferred.\n\n    - If either `a` or `b` is 0-D (scalar), it is equivalent to\n      :func:`multiply` and using ``numpy.multiply(a, b)`` or ``a * b`` is\n      preferred.\n\n    - If `a` is an N-D array and `b` is a 1-D array, it is a sum product over\n      the last axis of `a` and `b`.\n\n    - If `a` is an N-D array and `b` is an M-D array (where ``M>=2``), it is a\n      sum product over the last axis of `a` and the second-to-last axis of\n      `b`::\n\n        dot(a, b)[i,j,k,m] = sum(a[i,j,:] * b[k,:,m])\n\n    It uses an optimized BLAS library when possible (see `numpy.linalg`).\n\n    Parameters\n    ----------\n    a : array_like\n        First argument.\n    b : array_like\n        Second argument.\n    out : ndarray, optional\n        Output argument. This must have the exact kind that would be returned\n        if it was not used. In particular, it must have the right type, must be\n        C-contiguous, and its dtype must be the dtype that would be returned\n        for `dot(a,b)`. This is a performance feature. Therefore, if these\n        conditions are not met, an exception is raised, instead of attempting\n        to be flexible.\n\n    Returns\n    -------\n    output : ndarray\n        Returns the dot product of `a` and `b`.  If `a` and `b` are both\n        scalars or both 1-D arrays then a scalar is returned; otherwise\n        an array is returned.\n        If `out` is given, then it is returned.\n\n    Raises\n    ------\n    ValueError\n        If the last dimension of `a` is not the same size as\n        the second-to-last dimension of `b`.\n\n    See Also\n    --------\n    vdot : Complex-conjugating dot product.\n    tensordot : Sum products over arbitrary axes.\n    einsum : Einstein summation convention.\n    matmul : '@' operator as method with out parameter.\n    linalg.multi_dot : Chained dot product.\n\n    Examples\n    --------\n    >>> np.dot(3, 4)\n    12\n\n    Neither argument is complex-conjugated:\n\n    >>> np.dot([2j, 3j], [2j, 3j])\n    (-13+0j)\n\n    For 2-D arrays it is the matrix product:\n\n    >>> a = [[1, 0], [0, 1]]\n    >>> b = [[4, 1], [2, 2]]\n    >>> np.dot(a, b)\n    array([[4, 1],\n           [2, 2]])\n\n    >>> a = np.arange(3*4*5*6).reshape((3,4,5,6))\n    >>> b = np.arange(3*4*5*6)[::-1].reshape((5,4,6,3))\n    >>> np.dot(a, b)[2,3,2,1,2,2]\n    499128\n    >>> sum(a[2,3,2,:] * b[1,2,:,2])\n    499128\n\n    \"\"\"\n    return (a, b, out)"}, {"module": "numpy.core.multiarray", "name": "vdot", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "a", "datatype": null}, {"name": "b", "datatype": null}], "source_code": "def vdot(a, b):\n    \"\"\"\n    vdot(a, b, /)\n\n    Return the dot product of two vectors.\n\n    The vdot(`a`, `b`) function handles complex numbers differently than\n    dot(`a`, `b`).  If the first argument is complex the complex conjugate\n    of the first argument is used for the calculation of the dot product.\n\n    Note that `vdot` handles multidimensional arrays differently than `dot`:\n    it does *not* perform a matrix product, but flattens input arguments\n    to 1-D vectors first. Consequently, it should only be used for vectors.\n\n    Parameters\n    ----------\n    a : array_like\n        If `a` is complex the complex conjugate is taken before calculation\n        of the dot product.\n    b : array_like\n        Second argument to the dot product.\n\n    Returns\n    -------\n    output : ndarray\n        Dot product of `a` and `b`.  Can be an int, float, or\n        complex depending on the types of `a` and `b`.\n\n    See Also\n    --------\n    dot : Return the dot product without using the complex conjugate of the\n          first argument.\n\n    Examples\n    --------\n    >>> a = np.array([1+2j,3+4j])\n    >>> b = np.array([5+6j,7+8j])\n    >>> np.vdot(a, b)\n    (70-8j)\n    >>> np.vdot(b, a)\n    (70+8j)\n\n    Note that higher-dimensional arrays are flattened!\n\n    >>> a = np.array([[1, 4], [5, 6]])\n    >>> b = np.array([[4, 1], [2, 2]])\n    >>> np.vdot(a, b)\n    30\n    >>> np.vdot(b, a)\n    30\n    >>> 1*4 + 4*1 + 5*2 + 6*2\n    30\n\n    \"\"\"\n    return (a, b)"}, {"module": "numpy.core.multiarray", "name": "bincount", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "x", "datatype": null}, {"name": "weights", "datatype": null}, {"name": "minlength", "datatype": null}], "source_code": "def bincount(x, weights=None, minlength=None):\n    \"\"\"\n    bincount(x, /, weights=None, minlength=0)\n\n    Count number of occurrences of each value in array of non-negative ints.\n\n    The number of bins (of size 1) is one larger than the largest value in\n    `x`. If `minlength` is specified, there will be at least this number\n    of bins in the output array (though it will be longer if necessary,\n    depending on the contents of `x`).\n    Each bin gives the number of occurrences of its index value in `x`.\n    If `weights` is specified the input array is weighted by it, i.e. if a\n    value ``n`` is found at position ``i``, ``out[n] += weight[i]`` instead\n    of ``out[n] += 1``.\n\n    Parameters\n    ----------\n    x : array_like, 1 dimension, nonnegative ints\n        Input array.\n    weights : array_like, optional\n        Weights, array of the same shape as `x`.\n    minlength : int, optional\n        A minimum number of bins for the output array.\n\n        .. versionadded:: 1.6.0\n\n    Returns\n    -------\n    out : ndarray of ints\n        The result of binning the input array.\n        The length of `out` is equal to ``np.amax(x)+1``.\n\n    Raises\n    ------\n    ValueError\n        If the input is not 1-dimensional, or contains elements with negative\n        values, or if `minlength` is negative.\n    TypeError\n        If the type of the input is float or complex.\n\n    See Also\n    --------\n    histogram, digitize, unique\n\n    Examples\n    --------\n    >>> np.bincount(np.arange(5))\n    array([1, 1, 1, 1, 1])\n    >>> np.bincount(np.array([0, 1, 1, 3, 2, 1, 7]))\n    array([1, 3, 1, 1, 0, 0, 0, 1])\n\n    >>> x = np.array([0, 1, 1, 3, 2, 1, 7, 23])\n    >>> np.bincount(x).size == np.amax(x)+1\n    True\n\n    The input array needs to be of integer dtype, otherwise a\n    TypeError is raised:\n\n    >>> np.bincount(np.arange(5, dtype=float))\n    Traceback (most recent call last):\n      ...\n    TypeError: Cannot cast array data from dtype('float64') to dtype('int64')\n    according to the rule 'safe'\n\n    A possible use of ``bincount`` is to perform sums over\n    variable-size chunks of an array, using the ``weights`` keyword.\n\n    >>> w = np.array([0.3, 0.5, 0.2, 0.7, 1., -0.6]) # weights\n    >>> x = np.array([0, 1, 1, 2, 2, 2])\n    >>> np.bincount(x,  weights=w)\n    array([ 0.3,  0.7,  1.1])\n\n    \"\"\"\n    return (x, weights)"}, {"module": "numpy.core.multiarray", "name": "ravel_multi_index", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "multi_index", "datatype": null}, {"name": "dims", "datatype": null}, {"name": "mode", "datatype": null}, {"name": "order", "datatype": null}], "source_code": "def ravel_multi_index(multi_index, dims, mode=None, order=None):\n    \"\"\"\n    ravel_multi_index(multi_index, dims, mode='raise', order='C')\n\n    Converts a tuple of index arrays into an array of flat\n    indices, applying boundary modes to the multi-index.\n\n    Parameters\n    ----------\n    multi_index : tuple of array_like\n        A tuple of integer arrays, one array for each dimension.\n    dims : tuple of ints\n        The shape of array into which the indices from ``multi_index`` apply.\n    mode : {'raise', 'wrap', 'clip'}, optional\n        Specifies how out-of-bounds indices are handled.  Can specify\n        either one mode or a tuple of modes, one mode per index.\n\n        * 'raise' -- raise an error (default)\n        * 'wrap' -- wrap around\n        * 'clip' -- clip to the range\n\n        In 'clip' mode, a negative index which would normally\n        wrap will clip to 0 instead.\n    order : {'C', 'F'}, optional\n        Determines whether the multi-index should be viewed as\n        indexing in row-major (C-style) or column-major\n        (Fortran-style) order.\n\n    Returns\n    -------\n    raveled_indices : ndarray\n        An array of indices into the flattened version of an array\n        of dimensions ``dims``.\n\n    See Also\n    --------\n    unravel_index\n\n    Notes\n    -----\n    .. versionadded:: 1.6.0\n\n    Examples\n    --------\n    >>> arr = np.array([[3,6,6],[4,5,1]])\n    >>> np.ravel_multi_index(arr, (7,6))\n    array([22, 41, 37])\n    >>> np.ravel_multi_index(arr, (7,6), order='F')\n    array([31, 41, 13])\n    >>> np.ravel_multi_index(arr, (4,6), mode='clip')\n    array([22, 23, 19])\n    >>> np.ravel_multi_index(arr, (4,4), mode=('clip','wrap'))\n    array([12, 13, 13])\n\n    >>> np.ravel_multi_index((3,1,4,1), (6,7,8,9))\n    1621\n    \"\"\"\n    return multi_index"}, {"module": "numpy.core.multiarray", "name": "unravel_index", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "indices", "datatype": null}, {"name": "shape", "datatype": null}, {"name": "order", "datatype": null}], "source_code": "def unravel_index(indices, shape=None, order=None):\n    \"\"\"\n    unravel_index(indices, shape, order='C')\n\n    Converts a flat index or array of flat indices into a tuple\n    of coordinate arrays.\n\n    Parameters\n    ----------\n    indices : array_like\n        An integer array whose elements are indices into the flattened\n        version of an array of dimensions ``shape``. Before version 1.6.0,\n        this function accepted just one index value.\n    shape : tuple of ints\n        The shape of the array to use for unraveling ``indices``.\n\n        .. versionchanged:: 1.16.0\n            Renamed from ``dims`` to ``shape``.\n\n    order : {'C', 'F'}, optional\n        Determines whether the indices should be viewed as indexing in\n        row-major (C-style) or column-major (Fortran-style) order.\n\n        .. versionadded:: 1.6.0\n\n    Returns\n    -------\n    unraveled_coords : tuple of ndarray\n        Each array in the tuple has the same shape as the ``indices``\n        array.\n\n    See Also\n    --------\n    ravel_multi_index\n\n    Examples\n    --------\n    >>> np.unravel_index([22, 41, 37], (7,6))\n    (array([3, 6, 6]), array([4, 5, 1]))\n    >>> np.unravel_index([31, 41, 13], (7,6), order='F')\n    (array([3, 6, 6]), array([4, 5, 1]))\n\n    >>> np.unravel_index(1621, (6,7,8,9))\n    (3, 1, 4, 1)\n\n    \"\"\"\n    return (indices,)"}, {"module": "numpy.core.multiarray", "name": "copyto", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "dst", "datatype": null}, {"name": "src", "datatype": null}, {"name": "casting", "datatype": null}, {"name": "where", "datatype": null}], "source_code": "def copyto(dst, src, casting=None, where=None):\n    \"\"\"\n    copyto(dst, src, casting='same_kind', where=True)\n\n    Copies values from one array to another, broadcasting as necessary.\n\n    Raises a TypeError if the `casting` rule is violated, and if\n    `where` is provided, it selects which elements to copy.\n\n    .. versionadded:: 1.7.0\n\n    Parameters\n    ----------\n    dst : ndarray\n        The array into which values are copied.\n    src : array_like\n        The array from which values are copied.\n    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\n        Controls what kind of data casting may occur when copying.\n\n          * 'no' means the data types should not be cast at all.\n          * 'equiv' means only byte-order changes are allowed.\n          * 'safe' means only casts which can preserve values are allowed.\n          * 'same_kind' means only safe casts or casts within a kind,\n            like float64 to float32, are allowed.\n          * 'unsafe' means any data conversions may be done.\n    where : array_like of bool, optional\n        A boolean array which is broadcasted to match the dimensions\n        of `dst`, and selects elements to copy from `src` to `dst`\n        wherever it contains the value True.\n\n    Examples\n    --------\n    >>> A = np.array([4, 5, 6])\n    >>> B = [1, 2, 3]\n    >>> np.copyto(A, B)\n    >>> A\n    array([1, 2, 3])\n\n    >>> A = np.array([[1, 2, 3], [4, 5, 6]])\n    >>> B = [[4, 5, 6], [7, 8, 9]]\n    >>> np.copyto(A, B)\n    >>> A\n    array([[4, 5, 6],\n           [7, 8, 9]])\n\n    \"\"\"\n    return (dst, src, where)"}, {"module": "numpy.core.multiarray", "name": "putmask", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "mask", "datatype": null}, {"name": "values", "datatype": null}], "source_code": "def putmask(a, /, mask, values):\n    \"\"\"\n    putmask(a, mask, values)\n\n    Changes elements of an array based on conditional and input values.\n\n    Sets ``a.flat[n] = values[n]`` for each n where ``mask.flat[n]==True``.\n\n    If `values` is not the same size as `a` and `mask` then it will repeat.\n    This gives behavior different from ``a[mask] = values``.\n\n    Parameters\n    ----------\n    a : ndarray\n        Target array.\n    mask : array_like\n        Boolean mask array. It has to be the same shape as `a`.\n    values : array_like\n        Values to put into `a` where `mask` is True. If `values` is smaller\n        than `a` it will be repeated.\n\n    See Also\n    --------\n    place, put, take, copyto\n\n    Examples\n    --------\n    >>> x = np.arange(6).reshape(2, 3)\n    >>> np.putmask(x, x>2, x**2)\n    >>> x\n    array([[ 0,  1,  2],\n           [ 9, 16, 25]])\n\n    If `values` is smaller than `a` it is repeated:\n\n    >>> x = np.arange(5)\n    >>> np.putmask(x, x>1, [-33, -44])\n    >>> x\n    array([  0,   1, -33, -44, -33])\n\n    \"\"\"\n    return (a, mask, values)"}, {"module": "numpy.core.multiarray", "name": "packbits", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "a", "datatype": null}, {"name": "axis", "datatype": null}, {"name": "bitorder", "datatype": null}], "source_code": "def packbits(a, axis=None, bitorder='big'):\n    \"\"\"\n    packbits(a, /, axis=None, bitorder='big')\n\n    Packs the elements of a binary-valued array into bits in a uint8 array.\n\n    The result is padded to full bytes by inserting zero bits at the end.\n\n    Parameters\n    ----------\n    a : array_like\n        An array of integers or booleans whose elements should be packed to\n        bits.\n    axis : int, optional\n        The dimension over which bit-packing is done.\n        ``None`` implies packing the flattened array.\n    bitorder : {'big', 'little'}, optional\n        The order of the input bits. 'big' will mimic bin(val),\n        ``[0, 0, 0, 0, 0, 0, 1, 1] => 3 = 0b00000011``, 'little' will\n        reverse the order so ``[1, 1, 0, 0, 0, 0, 0, 0] => 3``.\n        Defaults to 'big'.\n\n        .. versionadded:: 1.17.0\n\n    Returns\n    -------\n    packed : ndarray\n        Array of type uint8 whose elements represent bits corresponding to the\n        logical (0 or nonzero) value of the input elements. The shape of\n        `packed` has the same number of dimensions as the input (unless `axis`\n        is None, in which case the output is 1-D).\n\n    See Also\n    --------\n    unpackbits: Unpacks elements of a uint8 array into a binary-valued output\n                array.\n\n    Examples\n    --------\n    >>> a = np.array([[[1,0,1],\n    ...                [0,1,0]],\n    ...               [[1,1,0],\n    ...                [0,0,1]]])\n    >>> b = np.packbits(a, axis=-1)\n    >>> b\n    array([[[160],\n            [ 64]],\n           [[192],\n            [ 32]]], dtype=uint8)\n\n    Note that in binary 160 = 1010 0000, 64 = 0100 0000, 192 = 1100 0000,\n    and 32 = 0010 0000.\n\n    \"\"\"\n    return (a,)"}, {"module": "numpy.core.multiarray", "name": "unpackbits", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "a", "datatype": null}, {"name": "axis", "datatype": null}, {"name": "count", "datatype": null}, {"name": "bitorder", "datatype": null}], "source_code": "def unpackbits(a, axis=None, count=None, bitorder='big'):\n    \"\"\"\n    unpackbits(a, /, axis=None, count=None, bitorder='big')\n\n    Unpacks elements of a uint8 array into a binary-valued output array.\n\n    Each element of `a` represents a bit-field that should be unpacked\n    into a binary-valued output array. The shape of the output array is\n    either 1-D (if `axis` is ``None``) or the same shape as the input\n    array with unpacking done along the axis specified.\n\n    Parameters\n    ----------\n    a : ndarray, uint8 type\n       Input array.\n    axis : int, optional\n        The dimension over which bit-unpacking is done.\n        ``None`` implies unpacking the flattened array.\n    count : int or None, optional\n        The number of elements to unpack along `axis`, provided as a way\n        of undoing the effect of packing a size that is not a multiple\n        of eight. A non-negative number means to only unpack `count`\n        bits. A negative number means to trim off that many bits from\n        the end. ``None`` means to unpack the entire array (the\n        default). Counts larger than the available number of bits will\n        add zero padding to the output. Negative counts must not\n        exceed the available number of bits.\n\n        .. versionadded:: 1.17.0\n\n    bitorder : {'big', 'little'}, optional\n        The order of the returned bits. 'big' will mimic bin(val),\n        ``3 = 0b00000011 => [0, 0, 0, 0, 0, 0, 1, 1]``, 'little' will reverse\n        the order to ``[1, 1, 0, 0, 0, 0, 0, 0]``.\n        Defaults to 'big'.\n\n        .. versionadded:: 1.17.0\n\n    Returns\n    -------\n    unpacked : ndarray, uint8 type\n       The elements are binary-valued (0 or 1).\n\n    See Also\n    --------\n    packbits : Packs the elements of a binary-valued array into bits in\n               a uint8 array.\n\n    Examples\n    --------\n    >>> a = np.array([[2], [7], [23]], dtype=np.uint8)\n    >>> a\n    array([[ 2],\n           [ 7],\n           [23]], dtype=uint8)\n    >>> b = np.unpackbits(a, axis=1)\n    >>> b\n    array([[0, 0, 0, 0, 0, 0, 1, 0],\n           [0, 0, 0, 0, 0, 1, 1, 1],\n           [0, 0, 0, 1, 0, 1, 1, 1]], dtype=uint8)\n    >>> c = np.unpackbits(a, axis=1, count=-3)\n    >>> c\n    array([[0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0],\n           [0, 0, 0, 1, 0]], dtype=uint8)\n\n    >>> p = np.packbits(b, axis=0)\n    >>> np.unpackbits(p, axis=0)\n    array([[0, 0, 0, 0, 0, 0, 1, 0],\n           [0, 0, 0, 0, 0, 1, 1, 1],\n           [0, 0, 0, 1, 0, 1, 1, 1],\n           [0, 0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0, 0],\n           [0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)\n    >>> np.array_equal(b, np.unpackbits(p, axis=0, count=b.shape[0]))\n    True\n\n    \"\"\"\n    return (a,)"}, {"module": "numpy.core.multiarray", "name": "shares_memory", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "a", "datatype": null}, {"name": "b", "datatype": null}, {"name": "max_work", "datatype": null}], "source_code": "def shares_memory(a, b, max_work=None):\n    \"\"\"\n    shares_memory(a, b, /, max_work=None)\n\n    Determine if two arrays share memory.\n\n    .. warning::\n\n       This function can be exponentially slow for some inputs, unless\n       `max_work` is set to a finite number or ``MAY_SHARE_BOUNDS``.\n       If in doubt, use `numpy.may_share_memory` instead.\n\n    Parameters\n    ----------\n    a, b : ndarray\n        Input arrays\n    max_work : int, optional\n        Effort to spend on solving the overlap problem (maximum number\n        of candidate solutions to consider). The following special\n        values are recognized:\n\n        max_work=MAY_SHARE_EXACT  (default)\n            The problem is solved exactly. In this case, the function returns\n            True only if there is an element shared between the arrays. Finding\n            the exact solution may take extremely long in some cases.\n        max_work=MAY_SHARE_BOUNDS\n            Only the memory bounds of a and b are checked.\n\n    Raises\n    ------\n    numpy.exceptions.TooHardError\n        Exceeded max_work.\n\n    Returns\n    -------\n    out : bool\n\n    See Also\n    --------\n    may_share_memory\n\n    Examples\n    --------\n    >>> x = np.array([1, 2, 3, 4])\n    >>> np.shares_memory(x, np.array([5, 6, 7]))\n    False\n    >>> np.shares_memory(x[::2], x)\n    True\n    >>> np.shares_memory(x[::2], x[1::2])\n    False\n\n    Checking whether two arrays share memory is NP-complete, and\n    runtime may increase exponentially in the number of\n    dimensions. Hence, `max_work` should generally be set to a finite\n    number, as it is possible to construct examples that take\n    extremely long to run:\n\n    >>> from numpy.lib.stride_tricks import as_strided\n    >>> x = np.zeros([192163377], dtype=np.int8)\n    >>> x1 = as_strided(x, strides=(36674, 61119, 85569), shape=(1049, 1049, 1049))\n    >>> x2 = as_strided(x[64023025:], strides=(12223, 12224, 1), shape=(1049, 1049, 1))\n    >>> np.shares_memory(x1, x2, max_work=1000)\n    Traceback (most recent call last):\n    ...\n    numpy.exceptions.TooHardError: Exceeded max_work\n\n    Running ``np.shares_memory(x1, x2)`` without `max_work` set takes\n    around 1 minute for this case. It is possible to find problems\n    that take still significantly longer.\n\n    \"\"\"\n    return (a, b)"}, {"module": "numpy.core.multiarray", "name": "may_share_memory", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "a", "datatype": null}, {"name": "b", "datatype": null}, {"name": "max_work", "datatype": null}], "source_code": "def may_share_memory(a, b, max_work=None):\n    \"\"\"\n    may_share_memory(a, b, /, max_work=None)\n\n    Determine if two arrays might share memory\n\n    A return of True does not necessarily mean that the two arrays\n    share any element.  It just means that they *might*.\n\n    Only the memory bounds of a and b are checked by default.\n\n    Parameters\n    ----------\n    a, b : ndarray\n        Input arrays\n    max_work : int, optional\n        Effort to spend on solving the overlap problem.  See\n        `shares_memory` for details.  Default for ``may_share_memory``\n        is to do a bounds check.\n\n    Returns\n    -------\n    out : bool\n\n    See Also\n    --------\n    shares_memory\n\n    Examples\n    --------\n    >>> np.may_share_memory(np.array([1,2]), np.array([5,8,9]))\n    False\n    >>> x = np.zeros([3, 4])\n    >>> np.may_share_memory(x[:,0], x[:,1])\n    True\n\n    \"\"\"\n    return (a, b)"}, {"module": "numpy.core.multiarray", "name": "is_busday", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "dates", "datatype": null}, {"name": "weekmask", "datatype": null}, {"name": "holidays", "datatype": null}, {"name": "busdaycal", "datatype": null}, {"name": "out", "datatype": null}], "source_code": "def is_busday(dates, weekmask=None, holidays=None, busdaycal=None, out=None):\n    \"\"\"\n    is_busday(dates, weekmask='1111100', holidays=None, busdaycal=None, out=None)\n\n    Calculates which of the given dates are valid days, and which are not.\n\n    .. versionadded:: 1.7.0\n\n    Parameters\n    ----------\n    dates : array_like of datetime64[D]\n        The array of dates to process.\n    weekmask : str or array_like of bool, optional\n        A seven-element array indicating which of Monday through Sunday are\n        valid days. May be specified as a length-seven list or array, like\n        [1,1,1,1,1,0,0]; a length-seven string, like '1111100'; or a string\n        like \"Mon Tue Wed Thu Fri\", made up of 3-character abbreviations for\n        weekdays, optionally separated by white space. Valid abbreviations\n        are: Mon Tue Wed Thu Fri Sat Sun\n    holidays : array_like of datetime64[D], optional\n        An array of dates to consider as invalid dates.  They may be\n        specified in any order, and NaT (not-a-time) dates are ignored.\n        This list is saved in a normalized form that is suited for\n        fast calculations of valid days.\n    busdaycal : busdaycalendar, optional\n        A `busdaycalendar` object which specifies the valid days. If this\n        parameter is provided, neither weekmask nor holidays may be\n        provided.\n    out : array of bool, optional\n        If provided, this array is filled with the result.\n\n    Returns\n    -------\n    out : array of bool\n        An array with the same shape as ``dates``, containing True for\n        each valid day, and False for each invalid day.\n\n    See Also\n    --------\n    busdaycalendar : An object that specifies a custom set of valid days.\n    busday_offset : Applies an offset counted in valid days.\n    busday_count : Counts how many valid days are in a half-open date range.\n\n    Examples\n    --------\n    >>> # The weekdays are Friday, Saturday, and Monday\n    ... np.is_busday(['2011-07-01', '2011-07-02', '2011-07-18'],\n    ...                 holidays=['2011-07-01', '2011-07-04', '2011-07-17'])\n    array([False, False,  True])\n    \"\"\"\n    return (dates, weekmask, holidays, out)"}, {"module": "numpy.core.multiarray", "name": "busday_offset", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "dates", "datatype": null}, {"name": "offsets", "datatype": null}, {"name": "roll", "datatype": null}, {"name": "weekmask", "datatype": null}, {"name": "holidays", "datatype": null}, {"name": "busdaycal", "datatype": null}, {"name": "out", "datatype": null}], "source_code": "def busday_offset(dates, offsets, roll=None, weekmask=None, holidays=None,\n                  busdaycal=None, out=None):\n    \"\"\"\n    busday_offset(dates, offsets, roll='raise', weekmask='1111100', holidays=None, busdaycal=None, out=None)\n\n    First adjusts the date to fall on a valid day according to\n    the ``roll`` rule, then applies offsets to the given dates\n    counted in valid days.\n\n    .. versionadded:: 1.7.0\n\n    Parameters\n    ----------\n    dates : array_like of datetime64[D]\n        The array of dates to process.\n    offsets : array_like of int\n        The array of offsets, which is broadcast with ``dates``.\n    roll : {'raise', 'nat', 'forward', 'following', 'backward', 'preceding', 'modifiedfollowing', 'modifiedpreceding'}, optional\n        How to treat dates that do not fall on a valid day. The default\n        is 'raise'.\n\n          * 'raise' means to raise an exception for an invalid day.\n          * 'nat' means to return a NaT (not-a-time) for an invalid day.\n          * 'forward' and 'following' mean to take the first valid day\n            later in time.\n          * 'backward' and 'preceding' mean to take the first valid day\n            earlier in time.\n          * 'modifiedfollowing' means to take the first valid day\n            later in time unless it is across a Month boundary, in which\n            case to take the first valid day earlier in time.\n          * 'modifiedpreceding' means to take the first valid day\n            earlier in time unless it is across a Month boundary, in which\n            case to take the first valid day later in time.\n    weekmask : str or array_like of bool, optional\n        A seven-element array indicating which of Monday through Sunday are\n        valid days. May be specified as a length-seven list or array, like\n        [1,1,1,1,1,0,0]; a length-seven string, like '1111100'; or a string\n        like \"Mon Tue Wed Thu Fri\", made up of 3-character abbreviations for\n        weekdays, optionally separated by white space. Valid abbreviations\n        are: Mon Tue Wed Thu Fri Sat Sun\n    holidays : array_like of datetime64[D], optional\n        An array of dates to consider as invalid dates.  They may be\n        specified in any order, and NaT (not-a-time) dates are ignored.\n        This list is saved in a normalized form that is suited for\n        fast calculations of valid days.\n    busdaycal : busdaycalendar, optional\n        A `busdaycalendar` object which specifies the valid days. If this\n        parameter is provided, neither weekmask nor holidays may be\n        provided.\n    out : array of datetime64[D], optional\n        If provided, this array is filled with the result.\n\n    Returns\n    -------\n    out : array of datetime64[D]\n        An array with a shape from broadcasting ``dates`` and ``offsets``\n        together, containing the dates with offsets applied.\n\n    See Also\n    --------\n    busdaycalendar : An object that specifies a custom set of valid days.\n    is_busday : Returns a boolean array indicating valid days.\n    busday_count : Counts how many valid days are in a half-open date range.\n\n    Examples\n    --------\n    >>> # First business day in October 2011 (not accounting for holidays)\n    ... np.busday_offset('2011-10', 0, roll='forward')\n    numpy.datetime64('2011-10-03')\n    >>> # Last business day in February 2012 (not accounting for holidays)\n    ... np.busday_offset('2012-03', -1, roll='forward')\n    numpy.datetime64('2012-02-29')\n    >>> # Third Wednesday in January 2011\n    ... np.busday_offset('2011-01', 2, roll='forward', weekmask='Wed')\n    numpy.datetime64('2011-01-19')\n    >>> # 2012 Mother's Day in Canada and the U.S.\n    ... np.busday_offset('2012-05', 1, roll='forward', weekmask='Sun')\n    numpy.datetime64('2012-05-13')\n\n    >>> # First business day on or after a date\n    ... np.busday_offset('2011-03-20', 0, roll='forward')\n    numpy.datetime64('2011-03-21')\n    >>> np.busday_offset('2011-03-22', 0, roll='forward')\n    numpy.datetime64('2011-03-22')\n    >>> # First business day after a date\n    ... np.busday_offset('2011-03-20', 1, roll='backward')\n    numpy.datetime64('2011-03-21')\n    >>> np.busday_offset('2011-03-22', 1, roll='backward')\n    numpy.datetime64('2011-03-23')\n    \"\"\"\n    return (dates, offsets, weekmask, holidays, out)"}, {"module": "numpy.core.multiarray", "name": "busday_count", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "begindates", "datatype": null}, {"name": "enddates", "datatype": null}, {"name": "weekmask", "datatype": null}, {"name": "holidays", "datatype": null}, {"name": "busdaycal", "datatype": null}, {"name": "out", "datatype": null}], "source_code": "def busday_count(begindates, enddates, weekmask=None, holidays=None,\n                 busdaycal=None, out=None):\n    \"\"\"\n    busday_count(begindates, enddates, weekmask='1111100', holidays=[], busdaycal=None, out=None)\n\n    Counts the number of valid days between `begindates` and\n    `enddates`, not including the day of `enddates`.\n\n    If ``enddates`` specifies a date value that is earlier than the\n    corresponding ``begindates`` date value, the count will be negative.\n\n    .. versionadded:: 1.7.0\n\n    Parameters\n    ----------\n    begindates : array_like of datetime64[D]\n        The array of the first dates for counting.\n    enddates : array_like of datetime64[D]\n        The array of the end dates for counting, which are excluded\n        from the count themselves.\n    weekmask : str or array_like of bool, optional\n        A seven-element array indicating which of Monday through Sunday are\n        valid days. May be specified as a length-seven list or array, like\n        [1,1,1,1,1,0,0]; a length-seven string, like '1111100'; or a string\n        like \"Mon Tue Wed Thu Fri\", made up of 3-character abbreviations for\n        weekdays, optionally separated by white space. Valid abbreviations\n        are: Mon Tue Wed Thu Fri Sat Sun\n    holidays : array_like of datetime64[D], optional\n        An array of dates to consider as invalid dates.  They may be\n        specified in any order, and NaT (not-a-time) dates are ignored.\n        This list is saved in a normalized form that is suited for\n        fast calculations of valid days.\n    busdaycal : busdaycalendar, optional\n        A `busdaycalendar` object which specifies the valid days. If this\n        parameter is provided, neither weekmask nor holidays may be\n        provided.\n    out : array of int, optional\n        If provided, this array is filled with the result.\n\n    Returns\n    -------\n    out : array of int\n        An array with a shape from broadcasting ``begindates`` and ``enddates``\n        together, containing the number of valid days between\n        the begin and end dates.\n\n    See Also\n    --------\n    busdaycalendar : An object that specifies a custom set of valid days.\n    is_busday : Returns a boolean array indicating valid days.\n    busday_offset : Applies an offset counted in valid days.\n\n    Examples\n    --------\n    >>> # Number of weekdays in January 2011\n    ... np.busday_count('2011-01', '2011-02')\n    21\n    >>> # Number of weekdays in 2011\n    >>> np.busday_count('2011', '2012')\n    260\n    >>> # Number of Saturdays in 2011\n    ... np.busday_count('2011', '2012', weekmask='Sat')\n    53\n    \"\"\"\n    return (begindates, enddates, weekmask, holidays, out)"}, {"module": "numpy.core.multiarray", "name": "datetime_as_string", "dependend_class": null, "function_calls": ["array_function_from_c_func_and_dispatcher"], "arguments": [{"name": "arr", "datatype": null}, {"name": "unit", "datatype": null}, {"name": "timezone", "datatype": null}, {"name": "casting", "datatype": null}], "source_code": "def datetime_as_string(arr, unit=None, timezone=None, casting=None):\n    \"\"\"\n    datetime_as_string(arr, unit=None, timezone='naive', casting='same_kind')\n\n    Convert an array of datetimes into an array of strings.\n\n    Parameters\n    ----------\n    arr : array_like of datetime64\n        The array of UTC timestamps to format.\n    unit : str\n        One of None, 'auto', or a :ref:`datetime unit <arrays.dtypes.dateunits>`.\n    timezone : {'naive', 'UTC', 'local'} or tzinfo\n        Timezone information to use when displaying the datetime. If 'UTC', end\n        with a Z to indicate UTC time. If 'local', convert to the local timezone\n        first, and suffix with a +-#### timezone offset. If a tzinfo object,\n        then do as with 'local', but use the specified timezone.\n    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}\n        Casting to allow when changing between datetime units.\n\n    Returns\n    -------\n    str_arr : ndarray\n        An array of strings the same shape as `arr`.\n\n    Examples\n    --------\n    >>> import pytz\n    >>> d = np.arange('2002-10-27T04:30', 4*60, 60, dtype='M8[m]')\n    >>> d\n    array(['2002-10-27T04:30', '2002-10-27T05:30', '2002-10-27T06:30',\n           '2002-10-27T07:30'], dtype='datetime64[m]')\n\n    Setting the timezone to UTC shows the same information, but with a Z suffix\n\n    >>> np.datetime_as_string(d, timezone='UTC')\n    array(['2002-10-27T04:30Z', '2002-10-27T05:30Z', '2002-10-27T06:30Z',\n           '2002-10-27T07:30Z'], dtype='<U35')\n\n    Note that we picked datetimes that cross a DST boundary. Passing in a\n    ``pytz`` timezone object will print the appropriate offset\n\n    >>> np.datetime_as_string(d, timezone=pytz.timezone('US/Eastern'))\n    array(['2002-10-27T00:30-0400', '2002-10-27T01:30-0400',\n           '2002-10-27T01:30-0500', '2002-10-27T02:30-0500'], dtype='<U39')\n\n    Passing in a unit will change the precision\n\n    >>> np.datetime_as_string(d, unit='h')\n    array(['2002-10-27T04', '2002-10-27T05', '2002-10-27T06', '2002-10-27T07'],\n          dtype='<U32')\n    >>> np.datetime_as_string(d, unit='s')\n    array(['2002-10-27T04:30:00', '2002-10-27T05:30:00', '2002-10-27T06:30:00',\n           '2002-10-27T07:30:00'], dtype='<U38')\n\n    'casting' can be used to specify whether precision can be changed\n\n    >>> np.datetime_as_string(d, unit='h', casting='safe')\n    Traceback (most recent call last):\n        ...\n    TypeError: Cannot create a datetime string as units 'h' from a NumPy\n    datetime with units 'm' according to the rule 'safe'\n    \"\"\"\n    return (arr,)"}, {"module": "numpy.core.numerictypes", "name": "maximum_sctype", "dependend_class": null, "function_calls": ["set_module", "obj2sctype", "_kind_name", "dtype"], "arguments": [{"name": "t", "datatype": null}], "source_code": "def maximum_sctype(t):\n    \"\"\"\n    Return the scalar type of highest precision of the same kind as the input.\n\n    Parameters\n    ----------\n    t : dtype or dtype specifier\n        The input data type. This can be a `dtype` object or an object that\n        is convertible to a `dtype`.\n\n    Returns\n    -------\n    out : dtype\n        The highest precision data type of the same kind (`dtype.kind`) as `t`.\n\n    See Also\n    --------\n    obj2sctype, mintypecode, sctype2char\n    dtype\n\n    Examples\n    --------\n    >>> np.maximum_sctype(int)\n    <class 'numpy.int64'>\n    >>> np.maximum_sctype(np.uint8)\n    <class 'numpy.uint64'>\n    >>> np.maximum_sctype(complex)\n    <class 'numpy.complex256'> # may vary\n\n    >>> np.maximum_sctype(str)\n    <class 'numpy.str_'>\n\n    >>> np.maximum_sctype('i2')\n    <class 'numpy.int64'>\n    >>> np.maximum_sctype('f4')\n    <class 'numpy.float128'> # may vary\n\n    \"\"\"\n    g = obj2sctype(t)\n    if g is None:\n        return t\n    t = g\n    base = _kind_name(dtype(t))\n    if base in sctypes:\n        return sctypes[base][-1]\n    else:\n        return t"}, {"module": "numpy.core.numerictypes", "name": "issctype", "dependend_class": null, "function_calls": ["set_module", "obj2sctype"], "arguments": [{"name": "rep", "datatype": null}], "source_code": "def issctype(rep):\n    \"\"\"\n    Determines whether the given object represents a scalar data-type.\n\n    Parameters\n    ----------\n    rep : any\n        If `rep` is an instance of a scalar dtype, True is returned. If not,\n        False is returned.\n\n    Returns\n    -------\n    out : bool\n        Boolean result of check whether `rep` is a scalar dtype.\n\n    See Also\n    --------\n    issubsctype, issubdtype, obj2sctype, sctype2char\n\n    Examples\n    --------\n    >>> np.issctype(np.int32)\n    True\n    >>> np.issctype(list)\n    False\n    >>> np.issctype(1.1)\n    False\n\n    Strings are also a scalar type:\n\n    >>> np.issctype(np.dtype('str'))\n    True\n\n    \"\"\"\n    if not isinstance(rep, (type, dtype)):\n        return False\n    try:\n        res = obj2sctype(rep)\n        if res and res != object_:\n            return True\n        return False\n    except Exception:\n        return False"}, {"module": "numpy.core.numerictypes", "name": "obj2sctype", "dependend_class": null, "function_calls": ["set_module", "dtype"], "arguments": [{"name": "rep", "datatype": null}, {"name": "default", "datatype": null}], "source_code": "def obj2sctype(rep, default=None):\n    \"\"\"\n    Return the scalar dtype or NumPy equivalent of Python type of an object.\n\n    Parameters\n    ----------\n    rep : any\n        The object of which the type is returned.\n    default : any, optional\n        If given, this is returned for objects whose types can not be\n        determined. If not given, None is returned for those objects.\n\n    Returns\n    -------\n    dtype : dtype or Python type\n        The data type of `rep`.\n\n    See Also\n    --------\n    sctype2char, issctype, issubsctype, issubdtype, maximum_sctype\n\n    Examples\n    --------\n    >>> np.obj2sctype(np.int32)\n    <class 'numpy.int32'>\n    >>> np.obj2sctype(np.array([1., 2.]))\n    <class 'numpy.float64'>\n    >>> np.obj2sctype(np.array([1.j]))\n    <class 'numpy.complex128'>\n\n    >>> np.obj2sctype(dict)\n    <class 'numpy.object_'>\n    >>> np.obj2sctype('string')\n\n    >>> np.obj2sctype(1, default=list)\n    <class 'list'>\n\n    \"\"\"\n    # prevent abstract classes being upcast\n    if isinstance(rep, type) and issubclass(rep, generic):\n        return rep\n    # extract dtype from arrays\n    if isinstance(rep, ndarray):\n        return rep.dtype.type\n    # fall back on dtype to convert\n    try:\n        res = dtype(rep)\n    except Exception:\n        return default\n    else:\n        return res.type"}, {"module": "numpy.core.numerictypes", "name": "issubclass_", "dependend_class": null, "function_calls": ["set_module"], "arguments": [{"name": "arg1", "datatype": null}, {"name": "arg2", "datatype": null}], "source_code": "def issubclass_(arg1, arg2):\n    \"\"\"\n    Determine if a class is a subclass of a second class.\n\n    `issubclass_` is equivalent to the Python built-in ``issubclass``,\n    except that it returns False instead of raising a TypeError if one\n    of the arguments is not a class.\n\n    Parameters\n    ----------\n    arg1 : class\n        Input class. True is returned if `arg1` is a subclass of `arg2`.\n    arg2 : class or tuple of classes.\n        Input class. If a tuple of classes, True is returned if `arg1` is a\n        subclass of any of the tuple elements.\n\n    Returns\n    -------\n    out : bool\n        Whether `arg1` is a subclass of `arg2` or not.\n\n    See Also\n    --------\n    issubsctype, issubdtype, issctype\n\n    Examples\n    --------\n    >>> np.issubclass_(np.int32, int)\n    False\n    >>> np.issubclass_(np.int32, float)\n    False\n    >>> np.issubclass_(np.float64, float)\n    True\n\n    \"\"\"\n    try:\n        return issubclass(arg1, arg2)\n    except TypeError:\n        return False"}, {"module": "numpy.core.numerictypes", "name": "issubsctype", "dependend_class": null, "function_calls": ["set_module", "obj2sctype", "obj2sctype"], "arguments": [{"name": "arg1", "datatype": null}, {"name": "arg2", "datatype": null}], "source_code": "def issubsctype(arg1, arg2):\n    \"\"\"\n    Determine if the first argument is a subclass of the second argument.\n\n    Parameters\n    ----------\n    arg1, arg2 : dtype or dtype specifier\n        Data-types.\n\n    Returns\n    -------\n    out : bool\n        The result.\n\n    See Also\n    --------\n    issctype, issubdtype, obj2sctype\n\n    Examples\n    --------\n    >>> np.issubsctype('S8', str)\n    False\n    >>> np.issubsctype(np.array([1]), int)\n    True\n    >>> np.issubsctype(np.array([1]), float)\n    False\n\n    \"\"\"\n    return issubclass(obj2sctype(arg1), obj2sctype(arg2))"}, {"module": "numpy.core.numerictypes", "name": "issubdtype", "dependend_class": null, "function_calls": ["set_module", "issubclass_", "issubclass_", "dtype", "dtype"], "arguments": [{"name": "arg1", "datatype": null}, {"name": "arg2", "datatype": null}], "source_code": "def issubdtype(arg1, arg2):\n    r\"\"\"\n    Returns True if first argument is a typecode lower/equal in type hierarchy.\n\n    This is like the builtin :func:`issubclass`, but for `dtype`\\ s.\n\n    Parameters\n    ----------\n    arg1, arg2 : dtype_like\n        `dtype` or object coercible to one\n\n    Returns\n    -------\n    out : bool\n\n    See Also\n    --------\n    :ref:`arrays.scalars` : Overview of the numpy type hierarchy.\n    issubsctype, issubclass_\n\n    Examples\n    --------\n    `issubdtype` can be used to check the type of arrays:\n\n    >>> ints = np.array([1, 2, 3], dtype=np.int32)\n    >>> np.issubdtype(ints.dtype, np.integer)\n    True\n    >>> np.issubdtype(ints.dtype, np.floating)\n    False\n\n    >>> floats = np.array([1, 2, 3], dtype=np.float32)\n    >>> np.issubdtype(floats.dtype, np.integer)\n    False\n    >>> np.issubdtype(floats.dtype, np.floating)\n    True\n\n    Similar types of different sizes are not subdtypes of each other:\n\n    >>> np.issubdtype(np.float64, np.float32)\n    False\n    >>> np.issubdtype(np.float32, np.float64)\n    False\n\n    but both are subtypes of `floating`:\n\n    >>> np.issubdtype(np.float64, np.floating)\n    True\n    >>> np.issubdtype(np.float32, np.floating)\n    True\n\n    For convenience, dtype-like objects are allowed too:\n\n    >>> np.issubdtype('S1', np.string_)\n    True\n    >>> np.issubdtype('i4', np.signedinteger)\n    True\n\n    \"\"\"\n    if not issubclass_(arg1, generic):\n        arg1 = dtype(arg1).type\n    if not issubclass_(arg2, generic):\n        arg2 = dtype(arg2).type\n\n    return issubclass(arg1, arg2)"}, {"module": "numpy.core.numerictypes", "name": "__getitem__", "dependend_class": "_typedict", "function_calls": ["dict.__getitem__", "obj2sctype"], "arguments": [{"name": "self", "datatype": null}, {"name": "obj", "datatype": null}], "source_code": "def __getitem__(self, obj):\n        return dict.__getitem__(self, obj2sctype(obj))"}, {"module": "numpy.core.numerictypes", "name": "_construct_lookups", "dependend_class": null, "function_calls": ["_concrete_typeinfo.items"], "arguments": [], "source_code": "def _construct_lookups():\n    for name, info in _concrete_typeinfo.items():\n        obj = info.type\n        nbytes[obj] = info.bits // 8\n        _alignment[obj] = info.alignment\n        if len(info) > 5:\n            _maxvals[obj] = info.max\n            _minvals[obj] = info.min\n        else:\n            _maxvals[obj] = None\n            _minvals[obj] = None"}, {"module": "numpy.core.numerictypes", "name": "sctype2char", "dependend_class": null, "function_calls": ["set_module", "obj2sctype", "dtype"], "arguments": [{"name": "sctype", "datatype": null}], "source_code": "def sctype2char(sctype):\n    \"\"\"\n    Return the string representation of a scalar dtype.\n\n    Parameters\n    ----------\n    sctype : scalar dtype or object\n        If a scalar dtype, the corresponding string character is\n        returned. If an object, `sctype2char` tries to infer its scalar type\n        and then return the corresponding string character.\n\n    Returns\n    -------\n    typechar : str\n        The string character corresponding to the scalar type.\n\n    Raises\n    ------\n    ValueError\n        If `sctype` is an object for which the type can not be inferred.\n\n    See Also\n    --------\n    obj2sctype, issctype, issubsctype, mintypecode\n\n    Examples\n    --------\n    >>> for sctype in [np.int32, np.double, np.complex_, np.string_, np.ndarray]:\n    ...     print(np.sctype2char(sctype))\n    l # may vary\n    d\n    D\n    S\n    O\n\n    >>> x = np.array([1., 2-1.j])\n    >>> np.sctype2char(x)\n    'D'\n    >>> np.sctype2char(list)\n    'O'\n\n    \"\"\"\n    sctype = obj2sctype(sctype)\n    if sctype is None:\n        raise ValueError(\"unrecognized type\")\n    if sctype not in _concrete_types:\n        # for compatibility\n        raise KeyError(sctype)\n    return dtype(sctype).char"}, {"module": "numpy.core.numerictypes", "name": "_scalar_type_key", "dependend_class": null, "function_calls": ["dtype", "dt.kind.lower"], "arguments": [{"name": "typ", "datatype": null}], "source_code": "def _scalar_type_key(typ):\n    \"\"\"A ``key`` function for `sorted`.\"\"\"\n    dt = dtype(typ)\n    return (dt.kind.lower(), dt.itemsize)"}, {"module": "numpy.core.numerictypes", "name": "_find_common_coerce", "dependend_class": null, "function_calls": ["_can_coerce_all", "__test_types.index"], "arguments": [{"name": "a", "datatype": null}, {"name": "b", "datatype": null}], "source_code": "def _find_common_coerce(a, b):\n    if a > b:\n        return a\n    try:\n        thisind = __test_types.index(a.char)\n    except ValueError:\n        return None\n    return _can_coerce_all([a, b], start=thisind)"}, {"module": "numpy.core.numerictypes", "name": "_can_coerce_all", "dependend_class": null, "function_calls": ["dtype"], "arguments": [{"name": "dtypelist", "datatype": null}, {"name": "start", "datatype": null}], "source_code": "def _can_coerce_all(dtypelist, start=0):\n    N = len(dtypelist)\n    if N == 0:\n        return None\n    if N == 1:\n        return dtypelist[0]\n    thisind = start\n    while thisind < __len_test_types:\n        newdtype = dtype(__test_types[thisind])\n        numcoerce = len([x for x in dtypelist if newdtype >= x])\n        if numcoerce == N:\n            return newdtype\n        thisind += 1\n    return None"}, {"module": "numpy.core.numerictypes", "name": "_register_types", "dependend_class": null, "function_calls": ["numbers.Integral.register", "numbers.Complex.register", "numbers.Real.register", "numbers.Number.register"], "arguments": [], "source_code": "def _register_types():\n    numbers.Integral.register(integer)\n    numbers.Complex.register(inexact)\n    numbers.Real.register(floating)\n    numbers.Number.register(number)"}, {"module": "numpy.core.numerictypes", "name": "find_common_type", "dependend_class": null, "function_calls": ["set_module", "warnings.warn", "_can_coerce_all", "_can_coerce_all", "dtype", "dtype", "_kind_list.index", "_kind_list.index", "_find_common_coerce"], "arguments": [{"name": "array_types", "datatype": null}, {"name": "scalar_types", "datatype": null}], "source_code": "def find_common_type(array_types, scalar_types):\n    \"\"\"\n    Determine common type following standard coercion rules.\n\n    .. deprecated:: NumPy 1.25\n\n        This function is deprecated, use `numpy.promote_types` or\n        `numpy.result_type` instead.  To achieve semantics for the\n        `scalar_types` argument, use `numpy.result_type` and pass the Python\n        values `0`, `0.0`, or `0j`.\n        This will give the same results in almost all cases.\n        More information and rare exception can be found in the\n        `NumPy 1.25 release notes <https://numpy.org/devdocs/release/1.25.0-notes.html>`_.\n\n    Parameters\n    ----------\n    array_types : sequence\n        A list of dtypes or dtype convertible objects representing arrays.\n    scalar_types : sequence\n        A list of dtypes or dtype convertible objects representing scalars.\n\n    Returns\n    -------\n    datatype : dtype\n        The common data type, which is the maximum of `array_types` ignoring\n        `scalar_types`, unless the maximum of `scalar_types` is of a\n        different kind (`dtype.kind`). If the kind is not understood, then\n        None is returned.\n\n    See Also\n    --------\n    dtype, common_type, can_cast, mintypecode\n\n    Examples\n    --------\n    >>> np.find_common_type([], [np.int64, np.float32, complex])\n    dtype('complex128')\n    >>> np.find_common_type([np.int64, np.float32], [])\n    dtype('float64')\n\n    The standard casting rules ensure that a scalar cannot up-cast an\n    array unless the scalar is of a fundamentally different kind of data\n    (i.e. under a different hierarchy in the data type hierarchy) then\n    the array:\n\n    >>> np.find_common_type([np.float32], [np.int64, np.float64])\n    dtype('float32')\n\n    Complex is of a different type, so it up-casts the float in the\n    `array_types` argument:\n\n    >>> np.find_common_type([np.float32], [complex])\n    dtype('complex128')\n\n    Type specifier strings are convertible to dtypes and can therefore\n    be used instead of dtypes:\n\n    >>> np.find_common_type(['f4', 'f4', 'i4'], ['c8'])\n    dtype('complex128')\n\n    \"\"\"\n    # Deprecated 2022-11-07, NumPy 1.25\n    warnings.warn(\n            \"np.find_common_type is deprecated.  Please use `np.result_type` \"\n            \"or `np.promote_types`.\\n\"\n            \"See https://numpy.org/devdocs/release/1.25.0-notes.html and the \"\n            \"docs for more information.  (Deprecated NumPy 1.25)\",\n            DeprecationWarning, stacklevel=2)\n\n    array_types = [dtype(x) for x in array_types]\n    scalar_types = [dtype(x) for x in scalar_types]\n\n    maxa = _can_coerce_all(array_types)\n    maxsc = _can_coerce_all(scalar_types)\n\n    if maxa is None:\n        return maxsc\n\n    if maxsc is None:\n        return maxa\n\n    try:\n        index_a = _kind_list.index(maxa.kind)\n        index_sc = _kind_list.index(maxsc.kind)\n    except ValueError:\n        return None\n\n    if index_sc > index_a:\n        return _find_common_coerce(maxsc, maxa)\n    else:\n        return maxa"}, {"module": "numpy.core.tests.test__exceptions", "name": "test_pickling", "dependend_class": "TestArrayMemoryError", "function_calls": ["_ArrayMemoryError", "pickle.loads", "np.dtype", "pickle.dumps"], "arguments": [{"name": "self", "datatype": null}], "source_code": "def test_pickling(self):\n        \"\"\" Test that _ArrayMemoryError can be pickled \"\"\"\n        error = _ArrayMemoryError((1023,), np.dtype(np.uint8))\n        res = pickle.loads(pickle.dumps(error))\n        assert res._total_size == error._total_size"}, {"module": "numpy.core.tests.test__exceptions", "name": "test_str", "dependend_class": "TestArrayMemoryError", "function_calls": ["_ArrayMemoryError", "np.dtype"], "arguments": [{"name": "self", "datatype": null}], "source_code": "def test_str(self):\n        e = _ArrayMemoryError((1023,), np.dtype(np.uint8))\n        str(e)"}, {"module": "numpy.core.tests.test__exceptions", "name": "test__size_to_string", "dependend_class": "TestArrayMemoryError", "function_calls": ["f", "f", "f", "f", "f", "f", "f", "f", "f", "f", "f", "f", "f"], "arguments": [{"name": "self", "datatype": null}], "source_code": "def test__size_to_string(self):\n        \"\"\" Test e._size_to_string \"\"\"\n        f = _ArrayMemoryError._size_to_string\n        Ki = 1024\n        assert f(0) == '0 bytes'\n        assert f(1) == '1 bytes'\n        assert f(1023) == '1023 bytes'\n        assert f(Ki) == '1.00 KiB'\n        assert f(Ki+1) == '1.00 KiB'\n        assert f(10*Ki) == '10.0 KiB'\n        assert f(int(999.4*Ki)) == '999. KiB'\n        assert f(int(1023.4*Ki)) == '1023. KiB'\n        assert f(int(1023.5*Ki)) == '1.00 MiB'\n        assert f(Ki*Ki) == '1.00 MiB'\n\n        # 1023.9999 Mib should round to 1 GiB\n        assert f(int(Ki*Ki*Ki*0.9999)) == '1.00 GiB'\n        assert f(Ki*Ki*Ki*Ki*Ki*Ki) == '1.00 EiB'\n        # larger than sys.maxsize, adding larger prefixes isn't going to help\n        # anyway.\n        assert f(Ki*Ki*Ki*Ki*Ki*Ki*123456) == '123456. EiB'"}, {"module": "numpy.core.tests.test__exceptions", "name": "test__total_size", "dependend_class": "TestArrayMemoryError", "function_calls": ["_ArrayMemoryError", "_ArrayMemoryError", "np.dtype", "np.dtype"], "arguments": [{"name": "self", "datatype": null}], "source_code": "def test__total_size(self):\n        \"\"\" Test e._total_size \"\"\"\n        e = _ArrayMemoryError((1,), np.dtype(np.uint8))\n        assert e._total_size == 1\n\n        e = _ArrayMemoryError((2, 4), np.dtype((np.uint64, 16)))\n        assert e._total_size == 1024"}, {"module": "numpy.core.tests.test__exceptions", "name": "test_pickling", "dependend_class": "TestUFuncNoLoopError", "function_calls": ["pickle.dumps"], "arguments": [{"name": "self", "datatype": null}], "source_code": "def test_pickling(self):\n        \"\"\" Test that _UFuncNoLoopError can be pickled \"\"\"\n        assert isinstance(pickle.dumps(_UFuncNoLoopError), bytes)"}, {"module": "numpy.core.tests.test__exceptions", "name": "test_attr", "dependend_class": "TestAxisError", "function_calls": ["np.AxisError"], "arguments": [{"name": "self", "datatype": null}, {"name": "args", "datatype": null}], "source_code": "def test_attr(self, args):\n        \"\"\"Validate attribute types.\"\"\"\n        exc = np.AxisError(*args)\n        if len(args) == 1:\n            assert exc.axis is None\n            assert exc.ndim is None\n        else:\n            axis, ndim, *_ = args\n            assert exc.axis == axis\n            assert exc.ndim == ndim"}, {"module": "numpy.core.tests.test__exceptions", "name": "test_pickling", "dependend_class": "TestAxisError", "function_calls": ["np.AxisError", "pickle.loads", "pickle.dumps"], "arguments": [{"name": "self", "datatype": null}, {"name": "args", "datatype": null}], "source_code": "def test_pickling(self, args):\n        \"\"\"Test that `AxisError` can be pickled.\"\"\"\n        exc = np.AxisError(*args)\n        exc2 = pickle.loads(pickle.dumps(exc))\n\n        assert type(exc) is type(exc2)\n        for name in (\"axis\", \"ndim\", \"args\"):\n            attr1 = getattr(exc, name)\n            attr2 = getattr(exc2, name)\n            assert attr1 == attr2, name"}, {"module": "numpy.core.tests.test_abc", "name": "test_abstract", "dependend_class": "TestABC", "function_calls": ["assert_", "assert_", "assert_", "assert_", "assert_", "assert_", "assert_"], "arguments": [{"name": "self", "datatype": null}], "source_code": "def test_abstract(self):\n        assert_(issubclass(np.number, numbers.Number))\n\n        assert_(issubclass(np.inexact, numbers.Complex))\n        assert_(issubclass(np.complexfloating, numbers.Complex))\n        assert_(issubclass(np.floating, numbers.Real))\n\n        assert_(issubclass(np.integer, numbers.Integral))\n        assert_(issubclass(np.signedinteger, numbers.Integral))\n        assert_(issubclass(np.unsignedinteger, numbers.Integral))"}, {"module": "numpy.core.tests.test_abc", "name": "test_floats", "dependend_class": "TestABC", "function_calls": ["assert_", "assert_", "assert_", "assert_", "t", "t"], "arguments": [{"name": "self", "datatype": null}], "source_code": "def test_floats(self):\n        for t in sctypes['float']:\n            assert_(isinstance(t(), numbers.Real),\n                    f\"{t.__name__} is not instance of Real\")\n            assert_(issubclass(t, numbers.Real),\n                    f\"{t.__name__} is not subclass of Real\")\n            assert_(not isinstance(t(), numbers.Rational),\n                    f\"{t.__name__} is instance of Rational\")\n            assert_(not issubclass(t, numbers.Rational),\n                    f\"{t.__name__} is subclass of Rational\")"}, {"module": "numpy.core.tests.test_abc", "name": "test_complex", "dependend_class": "TestABC", "function_calls": ["assert_", "assert_", "assert_", "assert_", "t", "t"], "arguments": [{"name": "self", "datatype": null}], "source_code": "def test_complex(self):\n        for t in sctypes['complex']:\n            assert_(isinstance(t(), numbers.Complex),\n                    f\"{t.__name__} is not instance of Complex\")\n            assert_(issubclass(t, numbers.Complex),\n                    f\"{t.__name__} is not subclass of Complex\")\n            assert_(not isinstance(t(), numbers.Real),\n                    f\"{t.__name__} is instance of Real\")\n            assert_(not issubclass(t, numbers.Real),\n                    f\"{t.__name__} is subclass of Real\")"}, {"module": "numpy.core.tests.test_abc", "name": "test_int", "dependend_class": "TestABC", "function_calls": ["assert_", "assert_", "t"], "arguments": [{"name": "self", "datatype": null}], "source_code": "def test_int(self):\n        for t in sctypes['int']:\n            assert_(isinstance(t(), numbers.Integral),\n                    f\"{t.__name__} is not instance of Integral\")\n            assert_(issubclass(t, numbers.Integral),\n                    f\"{t.__name__} is not subclass of Integral\")"}, {"module": "numpy.core.tests.test_abc", "name": "test_uint", "dependend_class": "TestABC", "function_calls": ["assert_", "assert_", "t"], "arguments": [{"name": "self", "datatype": null}], "source_code": "def test_uint(self):\n        for t in sctypes['uint']:\n            assert_(isinstance(t(), numbers.Integral),\n                    f\"{t.__name__} is not instance of Integral\")\n            assert_(issubclass(t, numbers.Integral),\n                    f\"{t.__name__} is not subclass of Integral\")"}, {"module": "numpy.core.tests.test_argparse", "name": "test_invalid_integers", "dependend_class": null, "function_calls": ["pytest.raises", "func", "pytest.raises", "func"], "arguments": [], "source_code": "def test_invalid_integers():\n    with pytest.raises(TypeError,\n            match=\"integer argument expected, got float\"):\n        func(1.)\n    with pytest.raises(OverflowError):\n        func(2**100)"}, {"module": "numpy.core.tests.test_argparse", "name": "test_missing_arguments", "dependend_class": null, "function_calls": ["pytest.raises", "func", "pytest.raises", "func", "pytest.raises", "func"], "arguments": [], "source_code": "def test_missing_arguments():\n    with pytest.raises(TypeError,\n            match=\"missing required positional argument 0\"):\n        func()\n    with pytest.raises(TypeError,\n            match=\"missing required positional argument 0\"):\n        func(arg2=1, arg3=4)\n    with pytest.raises(TypeError,\n            match=r\"missing required argument \\'arg2\\' \\(pos 1\\)\"):\n        func(1, arg3=5)"}, {"module": "numpy.core.tests.test_argparse", "name": "test_too_many_positional", "dependend_class": null, "function_calls": ["pytest.raises", "func"], "arguments": [], "source_code": "def test_too_many_positional():\n    # the second argument is positional but can be passed as keyword.\n    with pytest.raises(TypeError,\n            match=\"takes from 2 to 3 positional arguments but 4 were given\"):\n        func(1, 2, 3, 4)"}, {"module": "numpy.core.tests.test_argparse", "name": "test_multiple_values", "dependend_class": null, "function_calls": ["pytest.raises", "func"], "arguments": [], "source_code": "def test_multiple_values():\n    with pytest.raises(TypeError,\n            match=r\"given by name \\('arg2'\\) and position \\(position 1\\)\"):\n        func(1, 2, arg2=3)"}, {"module": "numpy.core.tests.test_argparse", "name": "test_string_fallbacks", "dependend_class": null, "function_calls": ["np.str_", "np.str_", "func", "pytest.raises", "func"], "arguments": [], "source_code": "def test_string_fallbacks():\n    # We can (currently?) use numpy strings to test the \"slow\" fallbacks\n    # that should normally not be taken due to string interning.\n    arg2 = np.str_(\"arg2\")\n    missing_arg = np.str_(\"missing_arg\")\n    func(1, **{arg2: 3})\n    with pytest.raises(TypeError,\n            match=\"got an unexpected keyword argument 'missing_arg'\"):\n        func(2, **{missing_arg: 3})"}, {"module": "numpy.core.tests.test_array_interface", "name": "get_module", "dependend_class": null, "function_calls": ["extbuild.build_and_import_extension", "sys.platform.startswith", "pytest.skip", "np.get_include"], "arguments": [{"name": "tmp_path", "datatype": null}], "source_code": "def get_module(tmp_path):\n    \"\"\" Some codes to generate data and manage temporary buffers use when\n    sharing with numpy via the array interface protocol.\n    \"\"\"\n\n    if not sys.platform.startswith('linux'):\n        pytest.skip('link fails on cygwin')\n\n    prologue = '''\n        #include <Python.h>\n        #define NPY_NO_DEPRECATED_API NPY_1_7_API_VERSION\n        #include <numpy/arrayobject.h>\n        #include <stdio.h>\n        #include <math.h>\n\n        NPY_NO_EXPORT\n        void delete_array_struct(PyObject *cap) {\n\n            /* get the array interface structure */\n            PyArrayInterface *inter = (PyArrayInterface*)\n                PyCapsule_GetPointer(cap, NULL);\n\n            /* get the buffer by which data was shared */\n            double *ptr = (double*)PyCapsule_GetContext(cap);\n\n            /* for the purposes of the regression test set the elements\n               to nan */\n            for (npy_intp i = 0; i < inter->shape[0]; ++i)\n                ptr[i] = nan(\"\");\n\n            /* free the shared buffer */\n            free(ptr);\n\n            /* free the array interface structure */\n            free(inter->shape);\n            free(inter);\n\n            fprintf(stderr, \"delete_array_struct\\\\ncap = %ld inter = %ld\"\n                \" ptr = %ld\\\\n\", (long)cap, (long)inter, (long)ptr);\n        }\n        '''\n\n    functions = [\n        (\"new_array_struct\", \"METH_VARARGS\", \"\"\"\n\n            long long n_elem = 0;\n            double value = 0.0;\n\n            if (!PyArg_ParseTuple(args, \"Ld\", &n_elem, &value)) {\n                Py_RETURN_NONE;\n            }\n\n            /* allocate and initialize the data to share with numpy */\n            long long n_bytes = n_elem*sizeof(double);\n            double *data = (double*)malloc(n_bytes);\n\n            if (!data) {\n                PyErr_Format(PyExc_MemoryError,\n                    \"Failed to malloc %lld bytes\", n_bytes);\n\n                Py_RETURN_NONE;\n            }\n\n            for (long long i = 0; i < n_elem; ++i) {\n                data[i] = value;\n            }\n\n            /* calculate the shape and stride */\n            int nd = 1;\n\n            npy_intp *ss = (npy_intp*)malloc(2*nd*sizeof(npy_intp));\n            npy_intp *shape = ss;\n            npy_intp *stride = ss + nd;\n\n            shape[0] = n_elem;\n            stride[0] = sizeof(double);\n\n            /* construct the array interface */\n            PyArrayInterface *inter = (PyArrayInterface*)\n                malloc(sizeof(PyArrayInterface));\n\n            memset(inter, 0, sizeof(PyArrayInterface));\n\n            inter->two = 2;\n            inter->nd = nd;\n            inter->typekind = 'f';\n            inter->itemsize = sizeof(double);\n            inter->shape = shape;\n            inter->strides = stride;\n            inter->data = data;\n            inter->flags = NPY_ARRAY_WRITEABLE | NPY_ARRAY_NOTSWAPPED |\n                           NPY_ARRAY_ALIGNED | NPY_ARRAY_C_CONTIGUOUS;\n\n            /* package into a capsule */\n            PyObject *cap = PyCapsule_New(inter, NULL, delete_array_struct);\n\n            /* save the pointer to the data */\n            PyCapsule_SetContext(cap, data);\n\n            fprintf(stderr, \"new_array_struct\\\\ncap = %ld inter = %ld\"\n                \" ptr = %ld\\\\n\", (long)cap, (long)inter, (long)data);\n\n            return cap;\n        \"\"\")\n        ]\n\n    more_init = \"import_array();\"\n\n    try:\n        import array_interface_testing\n        return array_interface_testing\n    except ImportError:\n        pass\n\n    # if it does not exist, build and load it\n    return extbuild.build_and_import_extension('array_interface_testing',\n                                               functions,\n                                               prologue=prologue,\n                                               include_dirs=[np.get_include()],\n                                               build_dir=tmp_path,\n                                               more_init=more_init)"}, {"module": "numpy.core.tests.test_array_interface", "name": "test_cstruct", "dependend_class": null, "function_calls": ["pytest.mark.skipif", "stderr.write", "data_source", "stderr.write", "stderr.write", "np.array", "stderr.write", "stderr.write", "stderr.write", "stderr.write", "stderr.write", "np.allclose", "stderr.write", "stderr.write", "stderr.write", "stderr.write", "stderr.write", "stderr.write", "stderr.write", "stderr.write", "stderr.write", "stderr.write", "np.allclose", "stderr.write", "stderr.write", "get_module.new_array_struct"], "arguments": [{"name": "get_module", "datatype": null}], "source_code": "def test_cstruct(get_module):\n\n    class data_source:\n        \"\"\"\n        This class is for testing the timing of the PyCapsule destructor\n        invoked when numpy release its reference to the shared data as part of\n        the numpy array interface protocol. If the PyCapsule destructor is\n        called early the shared data is freed and invalid memory accesses will\n        occur.\n        \"\"\"\n\n        def __init__(self, size, value):\n            self.size = size\n            self.value = value\n\n        @property\n        def __array_struct__(self):\n            return get_module.new_array_struct(self.size, self.value)\n\n    # write to the same stream as the C code\n    stderr = sys.__stderr__\n\n    # used to validate the shared data.\n    expected_value = -3.1415\n    multiplier = -10000.0\n\n    # create some data to share with numpy via the array interface\n    # assign the data an expected value.\n    stderr.write(' ---- create an object to share data ---- \\n')\n    buf = data_source(256, expected_value)\n    stderr.write(' ---- OK!\\n\\n')\n\n    # share the data\n    stderr.write(' ---- share data via the array interface protocol ---- \\n')\n    arr = np.array(buf, copy=False)\n    stderr.write('arr.__array_interface___ = %s\\n' % (\n                 str(arr.__array_interface__)))\n    stderr.write('arr.base = %s\\n' % (str(arr.base)))\n    stderr.write(' ---- OK!\\n\\n')\n\n    # release the source of the shared data. this will not release the data\n    # that was shared with numpy, that is done in the PyCapsule destructor.\n    stderr.write(' ---- destroy the object that shared data ---- \\n')\n    buf = None\n    stderr.write(' ---- OK!\\n\\n')\n\n    # check that we got the expected data. If the PyCapsule destructor we\n    # defined was prematurely called then this test will fail because our\n    # destructor sets the elements of the array to NaN before free'ing the\n    # buffer. Reading the values here may also cause a SEGV\n    assert np.allclose(arr, expected_value)\n\n    # read the data. If the PyCapsule destructor we defined was prematurely\n    # called then reading the values here may cause a SEGV and will be reported\n    # as invalid reads by valgrind\n    stderr.write(' ---- read shared data ---- \\n')\n    stderr.write('arr = %s\\n' % (str(arr)))\n    stderr.write(' ---- OK!\\n\\n')\n\n    # write to the shared buffer. If the shared data was prematurely deleted\n    # this will may cause a SEGV and valgrind will report invalid writes\n    stderr.write(' ---- modify shared data ---- \\n')\n    arr *= multiplier\n    expected_value *= multiplier\n    stderr.write('arr.__array_interface___ = %s\\n' % (\n                 str(arr.__array_interface__)))\n    stderr.write('arr.base = %s\\n' % (str(arr.base)))\n    stderr.write(' ---- OK!\\n\\n')\n\n    # read the data. If the shared data was prematurely deleted this\n    # will may cause a SEGV and valgrind will report invalid reads\n    stderr.write(' ---- read modified shared data ---- \\n')\n    stderr.write('arr = %s\\n' % (str(arr)))\n    stderr.write(' ---- OK!\\n\\n')\n\n    # check that we got the expected data. If the PyCapsule destructor we\n    # defined was prematurely called then this test will fail because our\n    # destructor sets the elements of the array to NaN before free'ing the\n    # buffer. Reading the values here may also cause a SEGV\n    assert np.allclose(arr, expected_value)\n\n    # free the shared data, the PyCapsule destructor should run here\n    stderr.write(' ---- free shared data ---- \\n')\n    arr = None\n    stderr.write(' ---- OK!\\n\\n')"}, {"module": "numpy.core.tests.test_arraymethod", "name": "test_invalid_arguments", "dependend_class": "TestResolveDescriptors", "function_calls": ["pytest.mark.parametrize", "pytest.raises", "self.method._resolve_descriptors", "np.dtype", "np.dtype"], "arguments": [{"name": "self", "datatype": null}, {"name": "args", "datatype": null}], "source_code": "def test_invalid_arguments(self, args):\n        with pytest.raises(TypeError):\n            self.method._resolve_descriptors(*args)"}, {"module": "numpy.core.tests.test_arraymethod", "name": "test_invalid_arguments", "dependend_class": "TestSimpleStridedCall", "function_calls": ["pytest.mark.parametrize", "pytest.raises", "self.method._simple_strided_call", "np.arange", "np.arange", "np.ones", "np.ones", "np.ones", "np.ones", "np.ones", "np.ones", "np.frombuffer", "np.frombuffer"], "arguments": [{"name": "self", "datatype": null}, {"name": "args", "datatype": null}, {"name": "error", "datatype": null}], "source_code": "def test_invalid_arguments(self, args, error):\n        # This is private API, which may be modified freely\n        with pytest.raises(error):\n            self.method._simple_strided_call(*args)"}, {"module": "numpy.core.tests.test_arraymethod", "name": "test_class_getitem", "dependend_class": "TestClassGetItem", "function_calls": [], "arguments": [{"name": "self", "datatype": null}, {"name": "cls", "datatype": 